{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting monai\n",
      "  Downloading monai-0.8.0-202111251823-py3-none-any.whl (709 kB)\n",
      "\u001b[K     |████████████████████████████████| 709 kB 538 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.8/site-packages (from monai) (1.11.0a0+b6df043)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from monai) (1.21.4)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.6->monai) (3.10.0.2)\n",
      "Installing collected packages: monai\n",
      "Successfully installed monai-0.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6_ZEBu_751r_"
   },
   "outputs": [],
   "source": [
    "#This is so that the plots are there along with the code in the notebook rather than a popup\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os.path import isfile,join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import torchvision.transforms as T\n",
    "from torch.nn.modules import padding\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from monai.metrics import HausdorffDistanceMetric,SurfaceDistanceMetric\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PMNVCoWIOFrH"
   },
   "outputs": [],
   "source": [
    "# For reproducing results\n",
    "seed = 42\n",
    "#random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzlbX_g4MKfj"
   },
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZjV8W8y19pJi"
   },
   "outputs": [],
   "source": [
    "# GPU | CPU\n",
    "def get_default_device():\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda:0')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data,device):\n",
    "    \n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    \n",
    "    return data.to(device,non_blocking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uXSjyGJ84VwK"
   },
   "outputs": [],
   "source": [
    "''' ----------------------------------------------------------\n",
    "    All the content here is intermediate data used to obtain df\n",
    "    None of these will be referenced later in the notebook \n",
    "    ---------------------------------------------------------- '''\n",
    "\n",
    "base_path = \"../processed/\"\n",
    "\n",
    "file_names = {\"image\": \"img_crp_v2.npy\", \n",
    "              \"esophagus\": \"/structure/Esophagus_crp_v2.npy\",\n",
    "              \"heart\": \"/structure/Heart_crp_v2.npy\",\n",
    "              \"lung_L\": \"/structure/Lung_L_crp_v2.npy\",\n",
    "              \"lung_R\": \"/structure/Lung_R_crp_v2.npy\",\n",
    "              \"spinal_cord\": \"/structure/SpinalCord_crp_v2.npy\"} \n",
    "\n",
    "dirs = [(base_path + f + \"/\") for f in os.listdir(base_path) if not isfile(join(base_path,f))]\n",
    "\n",
    "data = [[f + file_names[\"image\"],\n",
    "         f + file_names[\"esophagus\"],\n",
    "         f + file_names[\"heart\"],\n",
    "         f + file_names[\"lung_L\"],\n",
    "         f + file_names[\"lung_R\"],\n",
    "         f + file_names[\"spinal_cord\"]] for f in dirs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "lk_bn5ERlib4",
    "outputId": "aa9c72a9-f123-4124-8fca-de134f2e42a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Esophagus</th>\n",
       "      <th>Heart</th>\n",
       "      <th>Lung_L</th>\n",
       "      <th>Lung_R</th>\n",
       "      <th>SpinalCord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../processed/LCTSC-Train-S3-005/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005//structure/Eso...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005//structure/Hea...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005//structure/Spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../processed/LCTSC-Train-S1-004/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004//structure/Eso...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004//structure/Hea...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004//structure/Spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../processed/LCTSC-Train-S2-004/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004//structure/Eso...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004//structure/Hea...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004//structure/Spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../processed/LCTSC-Train-S3-008/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008//structure/Eso...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008//structure/Hea...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008//structure/Spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../processed/LCTSC-Train-S3-012/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012//structure/Eso...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012//structure/Hea...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012//structure/Spi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Image  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/img_crp_v2.npy   \n",
       "1  ../processed/LCTSC-Train-S1-004/img_crp_v2.npy   \n",
       "2  ../processed/LCTSC-Train-S2-004/img_crp_v2.npy   \n",
       "3  ../processed/LCTSC-Train-S3-008/img_crp_v2.npy   \n",
       "4  ../processed/LCTSC-Train-S3-012/img_crp_v2.npy   \n",
       "\n",
       "                                           Esophagus  \\\n",
       "0  ../processed/LCTSC-Train-S3-005//structure/Eso...   \n",
       "1  ../processed/LCTSC-Train-S1-004//structure/Eso...   \n",
       "2  ../processed/LCTSC-Train-S2-004//structure/Eso...   \n",
       "3  ../processed/LCTSC-Train-S3-008//structure/Eso...   \n",
       "4  ../processed/LCTSC-Train-S3-012//structure/Eso...   \n",
       "\n",
       "                                               Heart  \\\n",
       "0  ../processed/LCTSC-Train-S3-005//structure/Hea...   \n",
       "1  ../processed/LCTSC-Train-S1-004//structure/Hea...   \n",
       "2  ../processed/LCTSC-Train-S2-004//structure/Hea...   \n",
       "3  ../processed/LCTSC-Train-S3-008//structure/Hea...   \n",
       "4  ../processed/LCTSC-Train-S3-012//structure/Hea...   \n",
       "\n",
       "                                              Lung_L  \\\n",
       "0  ../processed/LCTSC-Train-S3-005//structure/Lun...   \n",
       "1  ../processed/LCTSC-Train-S1-004//structure/Lun...   \n",
       "2  ../processed/LCTSC-Train-S2-004//structure/Lun...   \n",
       "3  ../processed/LCTSC-Train-S3-008//structure/Lun...   \n",
       "4  ../processed/LCTSC-Train-S3-012//structure/Lun...   \n",
       "\n",
       "                                              Lung_R  \\\n",
       "0  ../processed/LCTSC-Train-S3-005//structure/Lun...   \n",
       "1  ../processed/LCTSC-Train-S1-004//structure/Lun...   \n",
       "2  ../processed/LCTSC-Train-S2-004//structure/Lun...   \n",
       "3  ../processed/LCTSC-Train-S3-008//structure/Lun...   \n",
       "4  ../processed/LCTSC-Train-S3-012//structure/Lun...   \n",
       "\n",
       "                                          SpinalCord  \n",
       "0  ../processed/LCTSC-Train-S3-005//structure/Spi...  \n",
       "1  ../processed/LCTSC-Train-S1-004//structure/Spi...  \n",
       "2  ../processed/LCTSC-Train-S2-004//structure/Spi...  \n",
       "3  ../processed/LCTSC-Train-S3-008//structure/Spi...  \n",
       "4  ../processed/LCTSC-Train-S3-012//structure/Spi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df contains all data regarding input data\n",
    "df = pd.DataFrame(data, columns = ['Image','Esophagus','Heart','Lung_L','Lung_R','SpinalCord'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtY6RXHnCvdK"
   },
   "source": [
    "## Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KHCzYFLMyfHs"
   },
   "outputs": [],
   "source": [
    "def Datagen_CT(df,img_size,seg_organ,window_size):\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        image = np.load(row[\"Image\"])\n",
    "        image = np.moveaxis(image,0,-1)\n",
    "        image = cv2.resize(image, (img_size,img_size))\n",
    "        image = np.swapaxes(image,0,-1)\n",
    "\n",
    "        mask = np.load(row[seg_organ])\n",
    "        mask = np.moveaxis(mask,0,-1)\n",
    "        mask = cv2.resize(mask , (img_size,img_size))\n",
    "        mask = np.swapaxes(mask,0,-1)\n",
    "\n",
    "        #Padding to fit window_size\n",
    "        image = np.concatenate((np.zeros((int(window_size/2),img_size,img_size)),image))\n",
    "        image = np.concatenate((image,np.zeros((int(window_size),img_size,img_size)))) #This is to ensure that the last valid slice can be reached\n",
    "        mask = np.concatenate((np.zeros((int(window_size/2),img_size,img_size)),mask))\n",
    "        mask = np.concatenate((mask,np.zeros((int(window_size/2),img_size,img_size))))\n",
    "\n",
    "        half_window = window_size//2\n",
    "        slice_index = half_window + 1 #the index of the next slice to be examined\n",
    "\n",
    "        while slice_index + window_size + half_window - 1 <= mask.shape[0]:#we put mask here because image has a longer size to adjust for the last slice\n",
    "            images = image[slice_index - half_window : slice_index + window_size + half_window,:,:]\n",
    "            masks = mask[slice_index: slice_index + window_size,:,:]\n",
    "\n",
    "            slice_index = slice_index + window_size\n",
    "            images = np.expand_dims(images,axis=1).astype('float32')\n",
    "            masks = np.expand_dims(masks,axis=1).astype('float32')\n",
    "\n",
    "            yield images, masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVmUybur4BHq"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZdGxJiOHAx8m"
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self,dim_in,dim_q,dim_k,linear_layer_needed,dim_o=0):\n",
    "        super(AttentionHead,self).__init__()\n",
    "        self.q = nn.Linear(dim_in,dim_q)\n",
    "        self.k = nn.Linear(dim_in,dim_k)\n",
    "        self.v = nn.Linear(dim_in,dim_k)\n",
    "        self.linear_layer_needed = linear_layer_needed\n",
    "        if linear_layer_needed:\n",
    "            self.linear = nn.Linear(dim_k,dim_o)\n",
    "\n",
    "    def forward(self,query,key,value):\n",
    "        query = self.q(query)\n",
    "        key = self.k(key)\n",
    "        value = self.v(value)\n",
    "\n",
    "        temp = query.matmul(key.transpose(0,1))\n",
    "        scale = query.size(-1) ** 0.5 #feature dimension\n",
    "        softmax = F.softmax(temp/scale, dim=-1)\n",
    "        attn_mat = softmax.matmul(value)\n",
    "        if self.linear_layer_needed:\n",
    "            return self.linear(attn_mat)\n",
    "        else:\n",
    "            return attn_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionGate(nn.Module):\n",
    "    \n",
    "    def __init__(self,F_g,F_x,F_int,pool_size):\n",
    "        super(AttentionGate,self).__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True)\n",
    "        self.W_x = nn.Conv2d(F_x,F_int,kernel_size=1,stride=1,padding=0,bias=True)\n",
    "        self.psi = nn.Conv2d(F_int,1,kernel_size=1,stride=1,padding=0,bias=True)\n",
    "        self.pool_size = pool_size\n",
    "        self.maxpool = nn.MaxPool2d((self.pool_size,self.pool_size))\n",
    "        \n",
    "        self.batchnorm_g = nn.BatchNorm2d(F_int)\n",
    "        self.batchnorm_x = nn.BatchNorm2d(F_int)\n",
    "    \n",
    "    def forward(self,g,x): #g : lower layer and x : corresponding encoder img \n",
    "        g1 = self.W_g(g)\n",
    "        g1 = self.batchnorm_g(g1)\n",
    "        \n",
    "        x1 = self.W_x(x)\n",
    "        x1 = self.batchnorm_x(x1)\n",
    "        x1 = self.maxpool(x1)\n",
    "        \n",
    "        interim = F.relu(g1+x1)\n",
    "        psi = self.psi(interim)\n",
    "        psi = torch.sigmoid(psi)\n",
    "        \n",
    "        psi = F.interpolate(psi,scale_factor=(self.pool_size,self.pool_size),mode='bilinear',align_corners=True)\n",
    "        return x * psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim_i,dim_o):\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(dim_i,dim_o,3,padding=\"same\")\n",
    "        self.batchnorm1 = nn.BatchNorm2d(dim_o)\n",
    "        self.conv2 = nn.Conv2d(dim_o,dim_o,3,padding=\"same\")\n",
    "        self.batchnorm2 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1 = self.conv1(x)\n",
    "        x1 = F.leaky_relu(x1)\n",
    "        x1 = self.batchnorm1(x1)\n",
    "        x1 = self.conv2(x1)\n",
    "        x1 = F.leaky_relu(x1)\n",
    "        x1 = self.batchnorm2(x1)\n",
    "        return x1\n",
    "\n",
    "class UNet_Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(UNet_Encoder,self).__init__()\n",
    "\n",
    "        self.enc1 = EncoderBlock(1,32)\n",
    "        self.enc2 = EncoderBlock(32,64)\n",
    "        self.enc3 = EncoderBlock(64,128)\n",
    "        self.enc4 = EncoderBlock(128,256)\n",
    "        self.enc5 = EncoderBlock(256,512)\n",
    "        self.enc6 = EncoderBlock(512,1024)\n",
    "        \n",
    "        self.maxpool_x2 = nn.MaxPool2d((2,2))\n",
    "        self.maxpool_x4 = nn.MaxPool2d((4,4))\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        x1 = self.enc1(x)\n",
    "\n",
    "        x2 = self.maxpool_x4(x1)\n",
    "        x2 = self.enc2(x2)\n",
    "        \n",
    "        x3 = self.maxpool_x4(x2)\n",
    "        x3 = self.enc3(x3)\n",
    "\n",
    "        x4 = self.maxpool_x4(x3)\n",
    "        x4 = self.enc4(x4)\n",
    "\n",
    "        x5 = self.maxpool_x2(x4)\n",
    "        x5 = self.enc5(x5)\n",
    "\n",
    "        x6 = self.maxpool_x2(x5)\n",
    "        x6 = self.enc6(x6)\n",
    "        \n",
    "        return (x1,x2,x3,x4,x5,x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim_i,dim_o,up_size):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        \n",
    "        self.trans_conv = nn.ConvTranspose2d(dim_i,dim_o,kernel_size=up_size,stride=up_size)\n",
    "        self.attn_gate = AttentionGate(F_g=dim_i,F_x=dim_o,F_int=dim_o,pool_size=up_size)\n",
    "        \n",
    "        self.conv_r1 = nn.Conv2d(dim_i,dim_o,kernel_size=3,padding=\"same\")\n",
    "        self.conv_r2 = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "        \n",
    "        self.batchnorm_r1 = nn.BatchNorm2d(dim_o)\n",
    "        self.batchnorm_r2 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "    def forward(self,x,x_enc):\n",
    "        xi = self.trans_conv(x)\n",
    "        xa = self.attn_gate(x,x_enc)\n",
    "        xi = torch.cat((xi,xa),dim=1) #concatenating to the channel dimension\n",
    "        \n",
    "        xi = self.conv_r1(xi)\n",
    "        xi = F.leaky_relu(xi)\n",
    "        xi = self.batchnorm_r1(xi)\n",
    "        \n",
    "        xi = self.conv_r2(xi)\n",
    "        xi = F.leaky_relu(xi)\n",
    "        xi = self.batchnorm_r2(xi)\n",
    "        \n",
    "        return xi\n",
    "        \n",
    "\n",
    "\n",
    "class UNet_Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(UNet_Decoder,self).__init__()\n",
    "        \n",
    "        #since last two maxpools are x4, the filter and strides of first two transpose convs are 4 each\n",
    "        self.dec1 = DecoderBlock(1024,512,2)\n",
    "        self.dec2 = DecoderBlock(512,256,2)\n",
    "        self.dec3 = DecoderBlock(256,128,4)\n",
    "        self.dec4 = DecoderBlock(128,64,4)\n",
    "        self.dec5 = DecoderBlock(64,32,4)\n",
    "\n",
    "    \n",
    "    def forward(self,x1,x2,x3,x4,x5,x_attn,window_size): \n",
    "        \n",
    "\n",
    "        xi = self.dec1(x_attn,x5[(window_size//2):-(window_size//2)])\n",
    "        xi = self.dec2(xi,x4[(window_size//2):-(window_size//2)])\n",
    "        xi = self.dec3(xi,x3[(window_size//2):-(window_size//2)])\n",
    "        xi = self.dec4(xi,x2[(window_size//2):-(window_size//2)])\n",
    "        xi = self.dec5(xi,x1[(window_size//2):-(window_size//2)])\n",
    "        \n",
    "        return xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xTNGGA9LkI1l"
   },
   "outputs": [],
   "source": [
    "#Input size is (window_size, 1, 512, 512)\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self,encoder,decoder,attention):\n",
    "        super(UNet,self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.attn_head1 = attention[0]\n",
    "        self.attn_head2 = attention[1]\n",
    "        self.decoder = decoder\n",
    "        self.conv_f = nn.Conv2d(32,1,kernel_size=1)\n",
    "\n",
    "    def attention_layer_calc(self,x_flatten,window_size):\n",
    "\n",
    "        i = 0\n",
    "        x_attn = None\n",
    "\n",
    "        while i + window_size <= x_flatten.shape[0]:\n",
    "            img_enc = x_flatten[i:i+window_size]\n",
    "            \n",
    "            #simple positional encoding\n",
    "            img_pos_enc = None\n",
    "            for ind1 in range(img_enc.shape[0]):\n",
    "                pos_temp = (img_enc[ind1] + ind1/img_enc.shape[0])[None,:]\n",
    "                if img_pos_enc is None:\n",
    "                    img_pos_enc = pos_temp\n",
    "                else:\n",
    "                    img_pos_enc = torch.cat((img_pos_enc,pos_temp))\n",
    "\n",
    "            temp1 = self.attn_head1(img_pos_enc,img_pos_enc,img_pos_enc)\n",
    "            temp2 = self.attn_head2(temp1,temp1,temp1)[window_size//2][None,:]\n",
    "\n",
    "            i = i + 1\n",
    "            if x_attn is None:\n",
    "                x_attn = temp2\n",
    "            else:\n",
    "                x_attn = torch.cat((x_attn,temp2))\n",
    "\n",
    "        x_attn = x_attn.reshape([x_attn.shape[0],1024,2,2])\n",
    "        return x_attn\n",
    "\n",
    "\n",
    "    def forward(self,x,window_size): #note: the entire batch is passed in \n",
    "\n",
    "        #Encoder\n",
    "        x1,x2,x3,x4,x5,x6 = self.encoder(x)\n",
    "\n",
    "        #Attention\n",
    "        x_flatten = torch.flatten(x6,start_dim=1)\n",
    "        \n",
    "        x_attn = self.attention_layer_calc(x_flatten,window_size)\n",
    "        x_attn = F.leaky_relu(x_attn)\n",
    "\n",
    "        #Decoder\n",
    "        xi_1 = self.decoder(x1,x2,x3,x4,x5,x_attn,window_size)\n",
    "\n",
    "        #Final\n",
    "        xf = self.conv_f(xi_1)\n",
    "        xf = torch.sigmoid(xf)\n",
    "        return xf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86xxpPwE4P2W"
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nbDjUsNK4SFZ"
   },
   "outputs": [],
   "source": [
    "def log_dice_loss(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "    \n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    result = torch.log((2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth))\n",
    "    dice_loss = -1 * torch.sum(result)/y_pred.shape[0]\n",
    "    return  dice_loss\n",
    "\n",
    "def dice_loss(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "    \n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    result = (2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth)\n",
    "    dice_loss = torch.sum(1-result)/y_pred.shape[0]\n",
    "    return  dice_loss\n",
    "\n",
    "def focal_loss(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "\n",
    "#     #dice metric\n",
    "#     intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "#     result = (2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth)\n",
    "#     dice_loss = -1 * torch.sum(torch.log(result))\n",
    "\n",
    "    #focal loss\n",
    "    gamma = 2\n",
    "    alpha = 0.25\n",
    "\n",
    "    bce_loss = F.binary_cross_entropy_with_logits(y_pred_f,y_true_f,reduction='none')\n",
    "    pt = torch.exp(-1 * bce_loss)\n",
    "\n",
    "    temp_at = to_device(torch.tensor([alpha,1-alpha]),get_default_device())\n",
    "    y_true_f = y_true_f.type(torch.long)\n",
    "    at = ((1-alpha) * (1 - y_true_f)) + (alpha * y_true_f)\n",
    "\n",
    "    F_loss = torch.sum(at * ((1-pt) ** gamma) * bce_loss)\n",
    "\n",
    "    return  (F_loss) / y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmi9pVgX1H_4"
   },
   "source": [
    "## Eval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "y03p8HLy1L__"
   },
   "outputs": [],
   "source": [
    "#IOU [Between 0-1: Higher value => Better results]\n",
    "def iou_metric(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "    \n",
    "    y_pred_f[y_pred_f >= 0.5] = 1\n",
    "    y_pred_f[y_pred_f < 0.5] = 0\n",
    "\n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    union = torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) - torch.sum(y_true_f * y_pred_f,1)\n",
    "    iou_score = torch.sum((intersection + smooth)/(union + smooth)) / y_pred.shape[0]\n",
    "    return  iou_score\n",
    "\n",
    "#Dice [Between 0-1: Higher value => Better results]\n",
    "def dice_metric(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "    \n",
    "    y_pred_f[y_pred_f >= 0.5] = 1\n",
    "    y_pred_f[y_pred_f < 0.5] = 0\n",
    "\n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    result = torch.sum((2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth))\n",
    "    dice_score = result/y_pred.shape[0]\n",
    "    return  dice_score\n",
    "\n",
    "#MSD [Between 0-infinity: Smaller value => Better results]\n",
    "def msd_metric(y_pred,y_true):\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    msd = SurfaceDistanceMetric(include_background=True)\n",
    "    val = torch.sum(msd(y_pred,y_true))\n",
    "\n",
    "    if val.isnan():\n",
    "        return to_device(torch.tensor(0),get_default_device())\n",
    "\n",
    "    return val\n",
    "\n",
    "#HD95 [Between 0-infinity: Smaller value => Better results]\n",
    "def hd95_metric(y_pred,y_true):\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    hd = HausdorffDistanceMetric(percentile=95,reduction=\"none\",include_background=False)\n",
    "    val = torch.sum(hd(y_pred,y_true))\n",
    "\n",
    "    if val.isnan():\n",
    "        return to_device(torch.tensor(0),get_default_device())\n",
    "\n",
    "    return val\n",
    "\n",
    "#Precision [Between 0-1: Larger value => Better results]\n",
    "def precision_metric(y_pred,y_true):\n",
    "    y_true = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred = torch.flatten(y_pred,start_dim=1)\n",
    "\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    tp = torch.sum(y_pred * y_true,1)\n",
    "    fp = torch.sum(y_pred * (1 - y_true),1)\n",
    "\n",
    "    if 0 in tp+fp:\n",
    "        return to_device(torch.tensor(0),get_default_device())\n",
    "\n",
    "    precision = torch.sum(tp/(tp+fp))/y_pred.shape[0]\n",
    "    return precision\n",
    "\n",
    "#Recall [Between 0-1: Larger value => Better results]\n",
    "def recall_metric(y_pred,y_true):\n",
    "    y_true = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred = torch.flatten(y_pred,start_dim=1)\n",
    "\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    tp = torch.sum(y_pred * y_true,1)\n",
    "    fn = torch.sum((1-y_pred) * y_true,1)\n",
    "\n",
    "    if 0 in tp+fn:\n",
    "        return to_device(torch.tensor(0),get_default_device())\n",
    "\n",
    "    recall = torch.sum(tp/(tp+fn))/y_pred.shape[0]\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-kEzBmcfvXT"
   },
   "source": [
    "## Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "REi6xcXTfu5H",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def eval(model,test_df,img_size,seg_organ,window_size,epoch=0,epochs=0):\n",
    "    #epoch and epoch size is passed if this function is called during training in between epochs\n",
    "    model.eval()\n",
    "    test_dataloader = Datagen_CT(df=test_df,img_size=img_size,seg_organ=seg_organ,window_size=window_size)\n",
    "\n",
    "    iou_val = 0\n",
    "    dice_val = 0\n",
    "    msd_val = 0\n",
    "    hd95_val = 0\n",
    "    pre_val = 0\n",
    "    re_val = 0\n",
    "\n",
    "    count = 0\n",
    "    for batch_idx, (X,y) in enumerate(test_dataloader):\n",
    "        X = to_device(torch.tensor(X, requires_grad=True),get_default_device())\n",
    "        y = to_device(torch.tensor(y, requires_grad=True),get_default_device())\n",
    "\n",
    "        output = model(X,window_size)\n",
    "        iou_val += iou_metric(output,y).item()\n",
    "        dice_val += dice_metric(output,y).item()\n",
    "        # msd_val += msd_metric(output,y).item()\n",
    "        # hd95_val += hd95_metric(output,y).item()\n",
    "        pre_val += precision_metric(output,y).item()\n",
    "        re_val += recall_metric(output,y).item()\n",
    "\n",
    "        count = count + 1\n",
    "    \n",
    "    print('-------------------------')\n",
    "    print('End of Epoch [{}/{}]   Dice Metric: {:.4f}  IoU Metric: {:.4f}  \\n  Precision Metric: {:.4f}  Recall Metric: {:.4f}'.format(epoch+1,epochs,dice_val/count,iou_val/count,pre_val/count,re_val/count))\n",
    "    print('\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    dice_val = dice_val/count\n",
    "    iou_val = iou_val/count\n",
    "    return dice_val, iou_val\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u66Hwr_H6Tcq"
   },
   "source": [
    "## Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6FHKWuS97dEa"
   },
   "outputs": [],
   "source": [
    "def fit(model,img_size,seg_organ,window_size,loss_fn,optimizer,scheduler,epochs,train_df,test_df,validate=False,print_every=1):\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        train_dataloader = Datagen_CT(df=train_df,img_size=img_size,seg_organ=seg_organ,window_size=window_size)\n",
    "    \n",
    "        for batch_idx, (X,y) in enumerate(train_dataloader):\n",
    "            X = to_device(torch.tensor(X, requires_grad=True),get_default_device())\n",
    "            y = to_device(torch.tensor(y, requires_grad=True),get_default_device())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X,window_size)\n",
    "            loss = loss_fn(output,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % print_every == 0:\n",
    "                print('Epoch [{}/{}]   Batch {}   Loss: {:.4f}    Max: {:.4f}'.format(epoch+1,epochs,batch_idx,loss.item(),torch.max(output)))\n",
    "                sys.stdout.flush()\n",
    "        \n",
    "\n",
    "                plt.subplot(1,3,1)\n",
    "                plt.imshow(X.cpu().detach().numpy()[window_size//2][0])\n",
    "\n",
    "                plt.subplot(1,3,2)\n",
    "                plt.imshow(y.cpu().detach().numpy()[0][0])\n",
    "\n",
    "                plt.subplot(1,3,3)\n",
    "                plt.imshow(output.cpu().detach().numpy()[0][0])\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "        print('Epoch [{}/{}]   Batch {}   Loss: {:.4f}    lr: {:.10f}'.format(epoch+1,epochs,batch_idx,loss.item(),optimizer.param_groups[0]['lr']))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        if validate:\n",
    "            dsc,iou = eval(model=model,test_df=test_df,img_size=img_size,seg_organ=seg_organ,window_size=window_size,epoch=epoch,epochs=epochs)\n",
    "            print('End of Epoch [{}/{}]   Dice Metric: {:.4f}  IoU Metric: {:.4f}'.format(epoch+1,epochs,dsc,iou))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zssyz5Jb7lUS"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "T27vlfDj6Rvk"
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "img_size = 512\n",
    "epochs = 100\n",
    "seg_organ = 'Lung_L'\n",
    "train_test_split = 0.8\n",
    "window_size = 5\n",
    "\n",
    "#Dataset Specific\n",
    "train_df = df[:int(train_test_split*df.shape[0])].reset_index(drop=True)\n",
    "test_df = df[int(train_test_split*df.shape[0]):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Specific\n",
    "enc = UNet_Encoder()\n",
    "dec = UNet_Decoder()\n",
    "attn = [AttentionHead(dim_in=4096,dim_q=1024,dim_k=1024,linear_layer_needed=False),\n",
    "        AttentionHead(dim_in=1024,dim_q=1024,dim_k=1024,linear_layer_needed=True,dim_o=4096)]\n",
    "model = UNet(enc,dec,attn)\n",
    "model = to_device(model,get_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('sma_lung_l_30epochs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Specific\n",
    "loss_fn = dice_loss\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[], gamma=0.1) #2,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FXFZK03-l1_"
   },
   "outputs": [],
   "source": [
    "fit(model=model, img_size=img_size, seg_organ=seg_organ, window_size=window_size,\n",
    "    loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler,\n",
    "    epochs=epochs, train_df=train_df, test_df=test_df, \n",
    "    validate=True, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(model=model,test_df=test_df,img_size=img_size,seg_organ=seg_organ,window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3opZPVo6Ipsm"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'adv_sma_wag_lung_l_100epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9teq9wX-OV6h"
   ],
   "name": "MultiSliceAttn_UNet_SpinalCord.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
