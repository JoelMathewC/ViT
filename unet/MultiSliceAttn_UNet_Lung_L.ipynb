{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: monai in /opt/conda/lib/python3.8/site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from monai) (1.21.4)\n",
      "Requirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.8/site-packages (from monai) (1.11.0a0+b6df043)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.6->monai) (3.10.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6_ZEBu_751r_"
   },
   "outputs": [],
   "source": [
    "#This is so that the plots are there along with the code in the notebook rather than a popup\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os.path import isfile,join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import torchvision.transforms as T\n",
    "from torch.nn.modules import padding\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from monai.metrics import HausdorffDistanceMetric,SurfaceDistanceMetric\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PMNVCoWIOFrH"
   },
   "outputs": [],
   "source": [
    "# For reproducing results\n",
    "seed = 58\n",
    "#random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzlbX_g4MKfj"
   },
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZjV8W8y19pJi"
   },
   "outputs": [],
   "source": [
    "# GPU | CPU\n",
    "def get_default_device():\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda:0')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data,device):\n",
    "    \n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    \n",
    "    return data.to(device,non_blocking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uXSjyGJ84VwK"
   },
   "outputs": [],
   "source": [
    "''' ----------------------------------------------------------\n",
    "    All the content here is intermediate data used to obtain df\n",
    "    None of these will be referenced later in the notebook \n",
    "    ---------------------------------------------------------- '''\n",
    "\n",
    "base_path = \"../processed/\"\n",
    "\n",
    "file_names = {\"image\": \"img_crp_v2.npy\", \n",
    "              \"esophagus\": \"/structure/Esophagus_crp_v2.npy\",\n",
    "              \"heart\": \"/structure/Heart_crp_v2.npy\",\n",
    "              \"lung_L\": \"/structure/Lung_L_crp_v2.npy\",\n",
    "              \"lung_R\": \"/structure/Lung_R_crp_v2.npy\",\n",
    "              \"spinal_cord\": \"/structure/SpinalCord_crp_v2.npy\"} \n",
    "\n",
    "dirs = [(base_path + f + \"/\") for f in os.listdir(base_path) if not isfile(join(base_path,f))]\n",
    "\n",
    "data = [[f + file_names[\"image\"],\n",
    "         f + file_names[\"esophagus\"],\n",
    "         f + file_names[\"heart\"],\n",
    "         f + file_names[\"lung_L\"],\n",
    "         f + file_names[\"lung_R\"],\n",
    "         f + file_names[\"spinal_cord\"]] for f in dirs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "lk_bn5ERlib4",
    "outputId": "aa9c72a9-f123-4124-8fca-de134f2e42a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Esophagus</th>\n",
       "      <th>Heart</th>\n",
       "      <th>Lung_L</th>\n",
       "      <th>Lung_R</th>\n",
       "      <th>SpinalCord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>processed/LCTSC-Train-S3-005/img_crp_v2.npy</td>\n",
       "      <td>processed/LCTSC-Train-S3-005//structure/Esopha...</td>\n",
       "      <td>processed/LCTSC-Train-S3-005//structure/Heart_...</td>\n",
       "      <td>processed/LCTSC-Train-S3-005//structure/Lung_L...</td>\n",
       "      <td>processed/LCTSC-Train-S3-005//structure/Lung_R...</td>\n",
       "      <td>processed/LCTSC-Train-S3-005//structure/Spinal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>processed/LCTSC-Train-S1-004/img_crp_v2.npy</td>\n",
       "      <td>processed/LCTSC-Train-S1-004//structure/Esopha...</td>\n",
       "      <td>processed/LCTSC-Train-S1-004//structure/Heart_...</td>\n",
       "      <td>processed/LCTSC-Train-S1-004//structure/Lung_L...</td>\n",
       "      <td>processed/LCTSC-Train-S1-004//structure/Lung_R...</td>\n",
       "      <td>processed/LCTSC-Train-S1-004//structure/Spinal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>processed/LCTSC-Train-S2-004/img_crp_v2.npy</td>\n",
       "      <td>processed/LCTSC-Train-S2-004//structure/Esopha...</td>\n",
       "      <td>processed/LCTSC-Train-S2-004//structure/Heart_...</td>\n",
       "      <td>processed/LCTSC-Train-S2-004//structure/Lung_L...</td>\n",
       "      <td>processed/LCTSC-Train-S2-004//structure/Lung_R...</td>\n",
       "      <td>processed/LCTSC-Train-S2-004//structure/Spinal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>processed/LCTSC-Train-S3-008/img_crp_v2.npy</td>\n",
       "      <td>processed/LCTSC-Train-S3-008//structure/Esopha...</td>\n",
       "      <td>processed/LCTSC-Train-S3-008//structure/Heart_...</td>\n",
       "      <td>processed/LCTSC-Train-S3-008//structure/Lung_L...</td>\n",
       "      <td>processed/LCTSC-Train-S3-008//structure/Lung_R...</td>\n",
       "      <td>processed/LCTSC-Train-S3-008//structure/Spinal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>processed/LCTSC-Train-S3-012/img_crp_v2.npy</td>\n",
       "      <td>processed/LCTSC-Train-S3-012//structure/Esopha...</td>\n",
       "      <td>processed/LCTSC-Train-S3-012//structure/Heart_...</td>\n",
       "      <td>processed/LCTSC-Train-S3-012//structure/Lung_L...</td>\n",
       "      <td>processed/LCTSC-Train-S3-012//structure/Lung_R...</td>\n",
       "      <td>processed/LCTSC-Train-S3-012//structure/Spinal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Image  \\\n",
       "0  processed/LCTSC-Train-S3-005/img_crp_v2.npy   \n",
       "1  processed/LCTSC-Train-S1-004/img_crp_v2.npy   \n",
       "2  processed/LCTSC-Train-S2-004/img_crp_v2.npy   \n",
       "3  processed/LCTSC-Train-S3-008/img_crp_v2.npy   \n",
       "4  processed/LCTSC-Train-S3-012/img_crp_v2.npy   \n",
       "\n",
       "                                           Esophagus  \\\n",
       "0  processed/LCTSC-Train-S3-005//structure/Esopha...   \n",
       "1  processed/LCTSC-Train-S1-004//structure/Esopha...   \n",
       "2  processed/LCTSC-Train-S2-004//structure/Esopha...   \n",
       "3  processed/LCTSC-Train-S3-008//structure/Esopha...   \n",
       "4  processed/LCTSC-Train-S3-012//structure/Esopha...   \n",
       "\n",
       "                                               Heart  \\\n",
       "0  processed/LCTSC-Train-S3-005//structure/Heart_...   \n",
       "1  processed/LCTSC-Train-S1-004//structure/Heart_...   \n",
       "2  processed/LCTSC-Train-S2-004//structure/Heart_...   \n",
       "3  processed/LCTSC-Train-S3-008//structure/Heart_...   \n",
       "4  processed/LCTSC-Train-S3-012//structure/Heart_...   \n",
       "\n",
       "                                              Lung_L  \\\n",
       "0  processed/LCTSC-Train-S3-005//structure/Lung_L...   \n",
       "1  processed/LCTSC-Train-S1-004//structure/Lung_L...   \n",
       "2  processed/LCTSC-Train-S2-004//structure/Lung_L...   \n",
       "3  processed/LCTSC-Train-S3-008//structure/Lung_L...   \n",
       "4  processed/LCTSC-Train-S3-012//structure/Lung_L...   \n",
       "\n",
       "                                              Lung_R  \\\n",
       "0  processed/LCTSC-Train-S3-005//structure/Lung_R...   \n",
       "1  processed/LCTSC-Train-S1-004//structure/Lung_R...   \n",
       "2  processed/LCTSC-Train-S2-004//structure/Lung_R...   \n",
       "3  processed/LCTSC-Train-S3-008//structure/Lung_R...   \n",
       "4  processed/LCTSC-Train-S3-012//structure/Lung_R...   \n",
       "\n",
       "                                          SpinalCord  \n",
       "0  processed/LCTSC-Train-S3-005//structure/Spinal...  \n",
       "1  processed/LCTSC-Train-S1-004//structure/Spinal...  \n",
       "2  processed/LCTSC-Train-S2-004//structure/Spinal...  \n",
       "3  processed/LCTSC-Train-S3-008//structure/Spinal...  \n",
       "4  processed/LCTSC-Train-S3-012//structure/Spinal...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df contains all data regarding input data\n",
    "df = pd.DataFrame(data, columns = ['Image','Esophagus','Heart','Lung_L','Lung_R','SpinalCord'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtY6RXHnCvdK"
   },
   "source": [
    "## Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KHCzYFLMyfHs"
   },
   "outputs": [],
   "source": [
    "def Datagen_CT(df,img_size,seg_organ,window_size):\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        image = np.load(row[\"Image\"])\n",
    "        image = np.moveaxis(image,0,-1)\n",
    "        image = cv2.resize(image, (img_size,img_size))\n",
    "        image = np.swapaxes(image,0,-1)\n",
    "\n",
    "        mask = np.load(row[seg_organ])\n",
    "        mask = np.moveaxis(mask,0,-1)\n",
    "        mask = cv2.resize(mask , (img_size,img_size))\n",
    "        mask = np.swapaxes(mask,0,-1)\n",
    "\n",
    "        #Padding to fit window_size\n",
    "        image = np.concatenate((np.zeros((int(window_size/2),img_size,img_size)),image))\n",
    "        image = np.concatenate((image,np.zeros((int(window_size/2),img_size,img_size))))\n",
    "        mask = np.concatenate((np.zeros((int(window_size/2),img_size,img_size)),mask))\n",
    "        mask = np.concatenate((mask,np.zeros((int(window_size/2),img_size,img_size))))\n",
    "\n",
    "        half_window = window_size//2\n",
    "        slice_index = half_window + 1 #the index of the next slice to be examined\n",
    "\n",
    "        while slice_index + window_size + half_window - 1 <= image.shape[0]:\n",
    "            images = image[slice_index - half_window : slice_index + window_size + half_window,:,:]\n",
    "            masks = mask[slice_index: slice_index + window_size,:,:]\n",
    "\n",
    "            slice_index = slice_index + window_size\n",
    "            images = np.expand_dims(images,axis=1).astype('float32')\n",
    "            masks = np.expand_dims(masks,axis=1).astype('float32')\n",
    "\n",
    "            yield images, masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVmUybur4BHq"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZdGxJiOHAx8m"
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self,dim_in,dim_q,dim_k):\n",
    "        super(AttentionHead,self).__init__()\n",
    "        self.q = nn.Linear(dim_in,dim_q)\n",
    "        self.k = nn.Linear(dim_in,dim_k)\n",
    "        self.v = nn.Linear(dim_in,dim_k)\n",
    "        self.linear = nn.Linear(dim_k,dim_in)\n",
    "\n",
    "    def forward(self,query,key,value):\n",
    "        query = self.q(query)\n",
    "        key = self.k(key)\n",
    "        value = self.v(value)\n",
    "\n",
    "        temp = query.matmul(key.transpose(0,1))\n",
    "        scale = query.size(-1) ** 0.5 #feature dimension\n",
    "        softmax = F.softmax(temp/scale, dim=-1)\n",
    "        attn_mat = softmax.matmul(value)\n",
    "        return self.linear(attn_mat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xTNGGA9LkI1l"
   },
   "outputs": [],
   "source": [
    "#Input size is (window_size, 1, 512, 512)\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(UNet,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,32,3,padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(32,32,3,padding=\"same\")\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32,64,3,padding=\"same\")\n",
    "        self.conv4 = nn.Conv2d(64,64,3,padding=\"same\")\n",
    "\n",
    "        self.conv5 = nn.Conv2d(64,128,3,padding=\"same\")\n",
    "        self.conv6 = nn.Conv2d(128,128,3,padding=\"same\")\n",
    "\n",
    "        self.conv7 = nn.Conv2d(128,256,3,padding=\"same\")\n",
    "        self.conv8 = nn.Conv2d(256,256,3,padding=\"same\")\n",
    "\n",
    "        self.conv9 = nn.Conv2d(256,512,3,padding=\"same\")\n",
    "        self.conv10 = nn.Conv2d(512,512,3,padding=\"same\")\n",
    "\n",
    "        self.conv11 = nn.Conv2d(512,1024,3,padding=\"same\")\n",
    "        self.conv12 = nn.Conv2d(1024,1024,3,padding=\"same\")\n",
    "\n",
    "        #since last two maxpools are x4, the filter and strides of first two transpose convs are 4 each\n",
    "        self.trans_conv1 = nn.ConvTranspose2d(1024,512,kernel_size=4,stride=4)\n",
    "        self.conv_r10 = nn.Conv2d(1024,512,kernel_size=3,padding=\"same\")\n",
    "        self.conv_r9 = nn.Conv2d(512,512,kernel_size=3,padding=\"same\")\n",
    "\n",
    "        self.trans_conv2 = nn.ConvTranspose2d(512,256,kernel_size=4,stride=4)\n",
    "        self.conv_r8 = nn.Conv2d(512,256,kernel_size=3,padding=\"same\")\n",
    "        self.conv_r7 = nn.Conv2d(256,256,kernel_size=3,padding=\"same\")\n",
    "\n",
    "        self.trans_conv3 = nn.ConvTranspose2d(256,128,kernel_size=2,stride=2)\n",
    "        self.conv_r6 = nn.Conv2d(256,128,kernel_size=3,padding=\"same\")\n",
    "        self.conv_r5 = nn.Conv2d(128,128,kernel_size=3,padding=\"same\")\n",
    "\n",
    "        self.trans_conv4 = nn.ConvTranspose2d(128,64,kernel_size=2,stride=2)\n",
    "        self.conv_r4 = nn.Conv2d(128,64,kernel_size=3,padding=\"same\")\n",
    "        self.conv_r3 = nn.Conv2d(64,64,kernel_size=3,padding=\"same\")\n",
    "\n",
    "        self.trans_conv5 = nn.ConvTranspose2d(64,32,kernel_size=2,stride=2)\n",
    "        self.conv_r2 = nn.Conv2d(64,32,kernel_size=3,padding=\"same\")\n",
    "        self.conv_r1 = nn.Conv2d(32,32,kernel_size=3,padding=\"same\")\n",
    "\n",
    "        self.conv_f = nn.Conv2d(32,1,kernel_size=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d((2,2))\n",
    "        self.maxpool_x4 = nn.MaxPool2d((4,4))\n",
    "\n",
    "        self.attn_head1 = AttentionHead(dim_in=16384,dim_q=8192,dim_k=8192)\n",
    "        # self.attn_head2 = AttentionHead(dim_in=16384,dim_q=8192,dim_k=8192)\n",
    "        # self.attn_head3 = AttentionHead(dim_in=16384,dim_q=8192,dim_k=8192)\n",
    "\n",
    "  \n",
    "    def attention_layer_calc(self,x_flatten,window_size):\n",
    "\n",
    "        i = 0\n",
    "        x_attn = None\n",
    "\n",
    "        while i + window_size <= x_flatten.shape[0]:\n",
    "            img_enc = x_flatten[i:i+window_size]\n",
    "            pos_enc = np.zeros(img_enc.shape)\n",
    "            emb_length = pos_enc.shape[1]\n",
    "\n",
    "            #calculating the value of positional embedding\n",
    "            for ind1 in range(pos_enc.shape[0]):\n",
    "                for ind2 in range(pos_enc.shape[1]):\n",
    "\n",
    "                    pos_enc_val = ind1/(10000**(2*ind2/emb_length))\n",
    "                    if ind1%2 == 0:\n",
    "                        pos_enc[ind1][ind2] = np.sin(pos_enc_val)\n",
    "                    else:\n",
    "                        pos_enc[ind1][ind2] = np.cos(pos_enc_val)\n",
    "      \n",
    "            pos_enc = to_device(torch.from_numpy(pos_enc.astype('float32')), get_default_device())\n",
    "            img_enc = img_enc + pos_enc\n",
    "\n",
    "            temp1 = self.attn_head1(img_enc,img_enc,img_enc)[window_size//2][None,:]\n",
    "            # temp2 = self.attn_head2(temp1,temp1,temp1)\n",
    "            # temp3 = self.attn_head3(temp2,temp2,temp2)[window_size//2][None,:]\n",
    "\n",
    "            i = i + 1\n",
    "            if x_attn is None:\n",
    "                print(\"TEMP1: \",temp1.shape)\n",
    "                x_attn = temp1\n",
    "            else:\n",
    "                x_attn = torch.cat((x_attn,temp1))\n",
    "                print(\"x_attn: \",x_attn.shape)\n",
    "\n",
    "        x_attn = x_attn.reshape([x_attn.shape[0],1024,4,4])\n",
    "        return x_attn\n",
    "\n",
    "\n",
    "    def forward(self,x,window_size): #note: the entire batch is passed in \n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = F.relu(x1)\n",
    "        x1 = self.conv2(x1)\n",
    "        x1 = F.relu(x1)\n",
    "\n",
    "        x2 = self.maxpool(x1)\n",
    "        x2 = self.conv3(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        x2 = self.conv4(x2)\n",
    "        x2 = F.relu(x2)\n",
    "\n",
    "        x3 = self.maxpool(x2)\n",
    "        x3 = self.conv5(x3)\n",
    "        x3 = F.relu(x3)\n",
    "        x3 = self.conv6(x3)\n",
    "        x3 = F.relu(x3)\n",
    "\n",
    "        x4 = self.maxpool(x3)\n",
    "        x4 = self.conv7(x4)\n",
    "        x4 = F.relu(x4)\n",
    "        x4 = self.conv8(x4)\n",
    "        x4 = F.relu(x4)\n",
    "\n",
    "        x5 = self.maxpool_x4(x4)\n",
    "        x5 = self.conv9(x5)\n",
    "        x5 = F.relu(x5)\n",
    "        x5 = self.conv10(x5)\n",
    "        x5 = F.relu(x5)\n",
    "\n",
    "        x6 = self.maxpool_x4(x5)\n",
    "        x6 = self.conv11(x6)\n",
    "        x6 = F.relu(x6)\n",
    "        x6 = self.conv12(x6)\n",
    "        x6 = F.relu(x6) #Size: 4x4x1024\n",
    "\n",
    "        #Attention\n",
    "        x_flatten = torch.flatten(x6,start_dim=1)\n",
    "        x_attn = self.attention_layer_calc(x_flatten,window_size)\n",
    "\n",
    "        #expansion\n",
    "        xi_5 = self.trans_conv1(x_attn)\n",
    "        xi_5 = torch.cat((xi_5,x5[(window_size//2):-(window_size//2)]),dim=1) #concatenating to the channel dimension\n",
    "        xi_5 = self.conv_r10(xi_5)\n",
    "        xi_5 = F.relu(xi_5)\n",
    "        xi_5 = self.conv_r9(xi_5)\n",
    "        xi_5 = F.relu(xi_5)\n",
    "\n",
    "        xi_4 = self.trans_conv2(xi_5)\n",
    "        xi_4 = torch.cat((xi_4,x4[(window_size//2):-(window_size//2)]),dim=1) \n",
    "        xi_4 = self.conv_r8(xi_4)\n",
    "        xi_4 = F.relu(xi_4)\n",
    "        xi_4 = self.conv_r7(xi_4)\n",
    "        xi_4 = F.relu(xi_4)\n",
    "\n",
    "        xi_3 = self.trans_conv3(xi_4)\n",
    "        xi_3 = torch.cat((xi_3,x3[(window_size//2):-(window_size//2)]), dim=1)\n",
    "        xi_3 = self.conv_r6(xi_3)\n",
    "        xi_3 = F.relu(xi_3)\n",
    "        xi_3 = self.conv_r5(xi_3)\n",
    "        xi_3 = F.relu(xi_3)\n",
    "\n",
    "        xi_2 = self.trans_conv4(xi_3)\n",
    "        xi_2 = torch.cat((xi_2,x2[(window_size//2):-(window_size//2)]), dim=1)\n",
    "        xi_2 = self.conv_r4(xi_2)\n",
    "        xi_2 = F.relu(xi_2)\n",
    "        xi_2 = self.conv_r3(xi_2)\n",
    "        xi_2 = F.relu(xi_2)\n",
    "\n",
    "        xi_1 = self.trans_conv5(xi_2)\n",
    "        xi_1 = torch.cat((xi_1,x1[(window_size//2):-(window_size//2)]), dim=1)\n",
    "        xi_1 = self.conv_r2(xi_1)\n",
    "        xi_1 = F.relu(xi_1)\n",
    "        xi_1 = self.conv_r1(xi_1)\n",
    "        xi_1 = F.relu(xi_1)\n",
    "\n",
    "        xf = self.conv_f(xi_1)\n",
    "        xf = torch.sigmoid(xf)\n",
    "\n",
    "\n",
    "        return xf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86xxpPwE4P2W"
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nbDjUsNK4SFZ"
   },
   "outputs": [],
   "source": [
    "def dice_loss(y_pred,y_true,smooth=1):\n",
    "    \n",
    "    print(\"YPRED: \",y_pred.shape)\n",
    "    print(\"YTRUE: \",y_true.shape)\n",
    "    \n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "\n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    result = torch.log((2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth))\n",
    "    dice_loss = -1 * torch.sum(result)/y_pred.shape[0]\n",
    "    return  dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmi9pVgX1H_4"
   },
   "source": [
    "## Eval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "y03p8HLy1L__"
   },
   "outputs": [],
   "source": [
    "#IOU [Between 0-1: Higher value => Better results]\n",
    "def iou_metric(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "\n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    union = torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) - torch.sum(y_true_f * y_pred_f,1)\n",
    "    iou_score = torch.sum((intersection + smooth)/(union + smooth)) / y_pred.shape[0]\n",
    "    return  iou_score\n",
    "\n",
    "#Dice [Between 0-1: Higher value => Better results]\n",
    "def dice_metric(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "\n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    result = torch.sum((2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth))\n",
    "    dice_score = result/y_pred.shape[0]\n",
    "    return  dice_score\n",
    "\n",
    "#MSD [Between 0-infinity: Smaller value => Better results]\n",
    "def msd_metric(y_pred,y_true):\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    msd = SurfaceDistanceMetric(include_background=True)\n",
    "    val = torch.sum(msd(y_pred,y_true))\n",
    "\n",
    "    if val.isnan():\n",
    "    return to_device(torch.tensor(0),get_default_device())\n",
    "\n",
    "    return val\n",
    "\n",
    "#HD95 [Between 0-infinity: Smaller value => Better results]\n",
    "def hd95_metric(y_pred,y_true):\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    hd = HausdorffDistanceMetric(percentile=95,reduction=\"none\",include_background=False)\n",
    "    val = torch.sum(hd(y_pred,y_true))\n",
    "\n",
    "    if val.isnan():\n",
    "        return to_device(torch.tensor(0),get_default_device())\n",
    "\n",
    "    return val\n",
    "\n",
    "#Precision [Between 0-1: Larger value => Better results]\n",
    "def precision_metric(y_pred,y_true):\n",
    "    y_true = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred = torch.flatten(y_pred,start_dim=1)\n",
    "\n",
    "    y_pred[y_pred > 0] = 1\n",
    "    y_pred[y_pred <= 0] = 0\n",
    "\n",
    "    tp = torch.sum(y_pred * y_true,1)\n",
    "    fp = torch.sum(y_pred * (1 - y_true),1)\n",
    "\n",
    "    if 0 in tp+fp:\n",
    "    return to_device(torch.tensor(0),get_default_device())\n",
    "\n",
    "    precision = torch.sum(tp/(tp+fp))/y_pred.shape[0]\n",
    "    return precision\n",
    "\n",
    "#Recall [Between 0-1: Larger value => Better results]\n",
    "def recall_metric(y_pred,y_true):\n",
    "    y_true = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred = torch.flatten(y_pred,start_dim=1)\n",
    "\n",
    "    y_pred[y_pred > 0] = 1\n",
    "    y_pred[y_pred <= 0] = 0\n",
    "\n",
    "    tp = torch.sum(y_pred * y_true,1)\n",
    "    fn = torch.sum((1-y_pred) * y_true,1)\n",
    "\n",
    "    if 0 in tp+fn:\n",
    "    return to_device(torch.tensor(0),get_default_device())\n",
    "\n",
    "    recall = torch.sum(tp/(tp+fn))/y_pred.shape[0]\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-kEzBmcfvXT"
   },
   "source": [
    "## Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "REi6xcXTfu5H"
   },
   "outputs": [],
   "source": [
    "def eval(model,test_df,img_size,seg_organ,window_size,epoch=0,epochs=0):\n",
    "    #epoch and epoch size is passed if this function is called during training in between epochs\n",
    "    model.eval()\n",
    "    test_dataloader = Datagen_CT(df=test_df,img_size=img_size,seg_organ=seg_organ,window_size=window_size)\n",
    "\n",
    "    iou_val = 0\n",
    "    dice_val = 0\n",
    "    msd_val = 0\n",
    "    hd95_val = 0\n",
    "    pre_val = 0\n",
    "    re_val = 0\n",
    "\n",
    "    count = 0\n",
    "    for batch_idx, (X,y) in enumerate(test_dataloader):\n",
    "        X = to_device(torch.tensor(X, requires_grad=True),get_default_device())\n",
    "        y = to_device(torch.tensor(y, requires_grad=True),get_default_device())\n",
    "\n",
    "        output = model(X,window_size)\n",
    "        iou_val += iou_metric(output,y).item()\n",
    "        dice_val += dice_metric(output,y).item()\n",
    "        # msd_val += msd_metric(output,y).item()\n",
    "        # hd95_val += hd95_metric(output,y).item()\n",
    "        pre_val += precision_metric(output,y).item()\n",
    "        re_val += recall_metric(output,y).item()\n",
    "\n",
    "        count = count + 1\n",
    "        break #<<<<<-------------REMOVE THIS\n",
    "\n",
    "    print('-------------------------')\n",
    "    print('Epoch [{}/{}]   Dice Metric: {:.4f}  IoU Metric: {:.4f}  \\n  Precision Metric: {:.4f}  Recall Metric: {:.4f}'.format(epoch+1,epochs,dice_val/count,iou_val/count,pre_val/count,re_val/count))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u66Hwr_H6Tcq"
   },
   "source": [
    "## Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6FHKWuS97dEa"
   },
   "outputs": [],
   "source": [
    "def fit(model,img_size,seg_organ,window_size,loss_fn,optimizer,scheduler,epochs,train_df,test_df,validate=False,print_every=1):\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        train_dataloader = Datagen_CT(df=train_df,img_size=img_size,seg_organ=seg_organ,window_size=window_size)\n",
    "    \n",
    "        for batch_idx, (X,y) in enumerate(train_dataloader):\n",
    "            X = to_device(torch.tensor(X, requires_grad=True),get_default_device())\n",
    "            y = to_device(torch.tensor(y, requires_grad=True),get_default_device())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X,window_size)\n",
    "            loss = loss_fn(output,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % print_every == 0:\n",
    "                print('Epoch [{}/{}]   Batch {}   Loss: {:.4f}    Max: {:.4f}'.format(epoch+1,epochs,batch_idx,loss.item(),torch.max(output)))\n",
    "\n",
    "        \n",
    "\n",
    "                plt.subplot(1,3,1)\n",
    "                plt.imshow(X.cpu().detach().numpy()[window_size//2][0])\n",
    "\n",
    "                plt.subplot(1,3,2)\n",
    "                plt.imshow(y.cpu().detach().numpy()[0][0])\n",
    "\n",
    "                plt.subplot(1,3,3)\n",
    "                plt.imshow(output.cpu().detach().numpy()[0][0])\n",
    "\n",
    "                plt.show()\n",
    "            \n",
    "            break #<<<<<-------------REMOVE THIS\n",
    "\n",
    "\n",
    "        print('Epoch [{}/{}]   Batch {}   Loss: {:.4f}    lr: {:.10f}'.format(epoch+1,epochs,batch_idx,loss.item(),optimizer.param_groups[0]['lr']))\n",
    "        scheduler.step()\n",
    "\n",
    "        if validate:\n",
    "            eval(model=model,test_df=test_df,img_size=img_size,seg_organ=seg_organ,window_size=window_size,epoch=epoch,epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zssyz5Jb7lUS"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "T27vlfDj6Rvk"
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "img_size = 512\n",
    "epochs = 10\n",
    "seg_organ = 'Lung_L'\n",
    "train_test_split = 0.8\n",
    "window_size = 5\n",
    "\n",
    "#Model Specific\n",
    "train_df = df[:int(train_test_split*df.shape[0])].reset_index(drop=True)\n",
    "test_df = df[int(train_test_split*df.shape[0]):].reset_index(drop=True)\n",
    "\n",
    "model = UNet()\n",
    "model = to_device(model,get_default_device())\n",
    "loss_fn = dice_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.000005)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2,6,10], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "6FXFZK03-l1_",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fit(model=model, img_size=img_size, seg_organ=seg_organ, window_size=window_size,\n",
    "    loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler,\n",
    "    epochs=epochs, train_df=train_df, test_df=test_df, \n",
    "    validate=True, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3opZPVo6Ipsm"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lung_l')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9teq9wX-OV6h"
   ],
   "name": "MultiSliceAttn_UNet_SpinalCord.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
