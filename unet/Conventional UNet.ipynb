{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAF5Ck2mRlWU",
    "outputId": "18dd66dc-fa23-46f0-8b19-d504d94c6e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: monai in /opt/conda/lib/python3.8/site-packages (0.8.0)\n",
      "Requirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.8/site-packages (from monai) (1.11.0a0+b6df043)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from monai) (1.21.4)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.6->monai) (3.10.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6_ZEBu_751r_"
   },
   "outputs": [],
   "source": [
    "#This is so that the plots are there along with the code in the notebook rather than a popup\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os.path import isfile,join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import torchvision.transforms as T\n",
    "from torch.nn.modules import padding\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from monai.metrics import HausdorffDistanceMetric,SurfaceDistanceMetric\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PMNVCoWIOFrH"
   },
   "outputs": [],
   "source": [
    "# For reproducing results\n",
    "seed = 42\n",
    "#random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fv36BQj_RnXf",
    "outputId": "b447a0b8-b695-48f8-c406-71b53c538735"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzlbX_g4MKfj"
   },
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZjV8W8y19pJi"
   },
   "outputs": [],
   "source": [
    "# GPU | CPU\n",
    "def get_default_device():\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda:0')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data,device):\n",
    "    \n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    \n",
    "    return data.to(device,non_blocking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uXSjyGJ84VwK"
   },
   "outputs": [],
   "source": [
    "''' ----------------------------------------------------------\n",
    "    All the content here is intermediate data used to obtain df\n",
    "    None of these will be referenced later in the notebook \n",
    "    ---------------------------------------------------------- '''\n",
    "\n",
    "base_path = \"../processed/\"\n",
    "#\"/content/drive/MyDrive/AI Club Project - Segmentation/processed/\"\n",
    "\n",
    "file_names = {\"image\": \"img_crp_v2.npy\", \n",
    "              \"esophagus\": \"/structure/Esophagus_crp_v2.npy\",\n",
    "              \"heart\": \"/structure/Heart_crp_v2.npy\",\n",
    "              \"lung_L\": \"/structure/Lung_L_crp_v2.npy\",\n",
    "              \"lung_R\": \"/structure/Lung_R_crp_v2.npy\",\n",
    "              \"spinal_cord\": \"/structure/SpinalCord_crp_v2.npy\"} \n",
    "\n",
    "dirs = [(base_path + f + \"/\") for f in os.listdir(base_path) if not isfile(join(base_path,f))]\n",
    "\n",
    "data = [[f + file_names[\"image\"],\n",
    "         f + file_names[\"esophagus\"],\n",
    "         f + file_names[\"heart\"],\n",
    "         f + file_names[\"lung_L\"],\n",
    "         f + file_names[\"lung_R\"],\n",
    "         f + file_names[\"spinal_cord\"]] for f in dirs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "lk_bn5ERlib4",
    "outputId": "44de3215-6bf7-42ea-9a1f-c615118a9adc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Esophagus</th>\n",
       "      <th>Heart</th>\n",
       "      <th>Lung_L</th>\n",
       "      <th>Lung_R</th>\n",
       "      <th>SpinalCord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../processed/LCTSC-Train-S3-005/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005//structure/Eso...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005//structure/Hea...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005//structure/Spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../processed/LCTSC-Train-S1-004/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004//structure/Eso...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004//structure/Hea...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004//structure/Spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../processed/LCTSC-Train-S2-004/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004//structure/Eso...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004//structure/Hea...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004//structure/Spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../processed/LCTSC-Train-S3-008/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008//structure/Eso...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008//structure/Hea...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008//structure/Spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../processed/LCTSC-Train-S3-012/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012//structure/Eso...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012//structure/Hea...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012//structure/Lun...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012//structure/Spi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Image  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/img_crp_v2.npy   \n",
       "1  ../processed/LCTSC-Train-S1-004/img_crp_v2.npy   \n",
       "2  ../processed/LCTSC-Train-S2-004/img_crp_v2.npy   \n",
       "3  ../processed/LCTSC-Train-S3-008/img_crp_v2.npy   \n",
       "4  ../processed/LCTSC-Train-S3-012/img_crp_v2.npy   \n",
       "\n",
       "                                           Esophagus  \\\n",
       "0  ../processed/LCTSC-Train-S3-005//structure/Eso...   \n",
       "1  ../processed/LCTSC-Train-S1-004//structure/Eso...   \n",
       "2  ../processed/LCTSC-Train-S2-004//structure/Eso...   \n",
       "3  ../processed/LCTSC-Train-S3-008//structure/Eso...   \n",
       "4  ../processed/LCTSC-Train-S3-012//structure/Eso...   \n",
       "\n",
       "                                               Heart  \\\n",
       "0  ../processed/LCTSC-Train-S3-005//structure/Hea...   \n",
       "1  ../processed/LCTSC-Train-S1-004//structure/Hea...   \n",
       "2  ../processed/LCTSC-Train-S2-004//structure/Hea...   \n",
       "3  ../processed/LCTSC-Train-S3-008//structure/Hea...   \n",
       "4  ../processed/LCTSC-Train-S3-012//structure/Hea...   \n",
       "\n",
       "                                              Lung_L  \\\n",
       "0  ../processed/LCTSC-Train-S3-005//structure/Lun...   \n",
       "1  ../processed/LCTSC-Train-S1-004//structure/Lun...   \n",
       "2  ../processed/LCTSC-Train-S2-004//structure/Lun...   \n",
       "3  ../processed/LCTSC-Train-S3-008//structure/Lun...   \n",
       "4  ../processed/LCTSC-Train-S3-012//structure/Lun...   \n",
       "\n",
       "                                              Lung_R  \\\n",
       "0  ../processed/LCTSC-Train-S3-005//structure/Lun...   \n",
       "1  ../processed/LCTSC-Train-S1-004//structure/Lun...   \n",
       "2  ../processed/LCTSC-Train-S2-004//structure/Lun...   \n",
       "3  ../processed/LCTSC-Train-S3-008//structure/Lun...   \n",
       "4  ../processed/LCTSC-Train-S3-012//structure/Lun...   \n",
       "\n",
       "                                          SpinalCord  \n",
       "0  ../processed/LCTSC-Train-S3-005//structure/Spi...  \n",
       "1  ../processed/LCTSC-Train-S1-004//structure/Spi...  \n",
       "2  ../processed/LCTSC-Train-S2-004//structure/Spi...  \n",
       "3  ../processed/LCTSC-Train-S3-008//structure/Spi...  \n",
       "4  ../processed/LCTSC-Train-S3-012//structure/Spi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df contains all data regarding input data\n",
    "df = pd.DataFrame(data, columns = ['Image','Esophagus','Heart','Lung_L','Lung_R','SpinalCord'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtY6RXHnCvdK"
   },
   "source": [
    "## Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KHCzYFLMyfHs"
   },
   "outputs": [],
   "source": [
    "def Datagen_CT(df,img_size,seg_organ,batch_size):\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        image = np.load(row[\"Image\"])\n",
    "        image = np.moveaxis(image,0,-1)\n",
    "        image = cv2.resize(image, (img_size,img_size))\n",
    "        image = np.swapaxes(image,0,-1)\n",
    "\n",
    "        mask = np.load(row[seg_organ])\n",
    "        mask = np.moveaxis(mask,0,-1)\n",
    "        mask = cv2.resize(mask , (img_size,img_size))\n",
    "        mask = np.swapaxes(mask,0,-1)\n",
    "\n",
    "        #Padding to fit batch_size\n",
    "#         image = np.concatenate((image,np.zeros((int(batch_size),img_size,img_size)))) #This is to ensure that the last valid slice can be reached\n",
    "#         mask = np.concatenate((mask,np.zeros((int(batch_size),img_size,img_size))))\n",
    "        \n",
    "        slice_index = 0 #the index of the next slice to be examined\n",
    "\n",
    "        while slice_index < image.shape[0]:#we put mask here because image has a longer size to adjust for the last slice\n",
    "            images = image[slice_index: slice_index + batch_size,:,:]\n",
    "            masks = mask[slice_index: slice_index + batch_size,:,:]\n",
    "\n",
    "            slice_index = slice_index + batch_size\n",
    "            images = np.expand_dims(images,axis=1).astype('float32')\n",
    "            masks = np.expand_dims(masks,axis=1).astype('float32')\n",
    "\n",
    "            yield images, masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVmUybur4BHq"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "H1hVHelvRlWc"
   },
   "outputs": [],
   "source": [
    "class AttentionGate(nn.Module):\n",
    "    \n",
    "    def __init__(self,F_g,F_x,F_int,pool_size):\n",
    "        super(AttentionGate,self).__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True)\n",
    "        self.W_x = nn.Conv2d(F_x,F_int,kernel_size=1,stride=1,padding=0,bias=True)\n",
    "        self.psi = nn.Conv2d(F_int,1,kernel_size=1,stride=1,padding=0,bias=True)\n",
    "        self.pool_size = pool_size\n",
    "        self.maxpool = nn.MaxPool2d((self.pool_size,self.pool_size))\n",
    "        \n",
    "        self.batchnorm_g = nn.BatchNorm2d(F_int)\n",
    "        self.batchnorm_x = nn.BatchNorm2d(F_int)\n",
    "    \n",
    "    def forward(self,g,x): #g : lower layer and x : corresponding encoder img\n",
    "        g1 = self.W_g(g)\n",
    "        g1 = self.batchnorm_g(g1)\n",
    "        \n",
    "        x1 = self.W_x(x)\n",
    "        x1 = self.batchnorm_x(x1)\n",
    "        x1 = self.maxpool(x1)\n",
    "        \n",
    "        interim = F.relu(g1+x1)\n",
    "        psi = self.psi(interim)\n",
    "        psi = torch.sigmoid(psi)\n",
    "        \n",
    "        psi = F.interpolate(psi,scale_factor=(self.pool_size,self.pool_size),mode='bilinear',align_corners=True)\n",
    "        return x * psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fTZ8r4G-RlWd"
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim_i,dim_o):\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(dim_i,dim_o,3,padding=\"same\")\n",
    "        self.batchnorm1 = nn.BatchNorm2d(dim_o)\n",
    "        self.conv2 = nn.Conv2d(dim_o,dim_o,3,padding=\"same\")\n",
    "        self.batchnorm2 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1 = self.conv1(x)\n",
    "        x1 = F.leaky_relu(x1)\n",
    "        x1 = self.batchnorm1(x1)\n",
    "        x1 = self.conv2(x1)\n",
    "        x1 = F.leaky_relu(x1)\n",
    "        x1 = self.batchnorm2(x1)\n",
    "        return x1\n",
    "\n",
    "class UNet_Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(UNet_Encoder,self).__init__()\n",
    "\n",
    "        self.enc1 = EncoderBlock(1,32)\n",
    "        self.enc2 = EncoderBlock(32,64)\n",
    "        self.enc3 = EncoderBlock(64,128)\n",
    "        self.enc4 = EncoderBlock(128,256)\n",
    "        self.enc5 = EncoderBlock(256,512)\n",
    "        self.enc6 = EncoderBlock(512,1024)\n",
    "        \n",
    "        self.strided_conv1 = nn.Conv2d(32,32,kernel_size=2,stride=2)\n",
    "        self.strided_conv2 = nn.Conv2d(64,64,kernel_size=2,stride=2)\n",
    "        self.strided_conv3 = nn.Conv2d(128,128,kernel_size=2,stride=2)\n",
    "        self.strided_conv4 = nn.Conv2d(256,256,kernel_size=2,stride=2)\n",
    "        self.strided_conv5 = nn.Conv2d(512,512,kernel_size=2,stride=2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        x1 = self.enc1(x)\n",
    "        \n",
    "        x2 = self.strided_conv1(x1)\n",
    "        x2 = F.leaky_relu(x2)\n",
    "        x2 = self.enc2(x2)\n",
    "        \n",
    "        x3 = self.strided_conv2(x2)\n",
    "        x3 = F.leaky_relu(x3)\n",
    "        x3 = self.enc3(x3)\n",
    "\n",
    "        x4 = self.strided_conv3(x3)\n",
    "        x4 = F.leaky_relu(x4)\n",
    "        x4 = self.enc4(x4)\n",
    "\n",
    "        x5 = self.strided_conv4(x4)\n",
    "        x5 = F.leaky_relu(x5)\n",
    "        x5 = self.enc5(x5)\n",
    "\n",
    "        x6 = self.strided_conv5(x5)\n",
    "        x6 = F.leaky_relu(x6)\n",
    "        x6 = self.enc6(x6)\n",
    "        \n",
    "        return (x1,x2,x3,x4,x5,x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RZ3-n4plRlWe"
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim_i,dim_o,up_size):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        \n",
    "        self.trans_conv = nn.ConvTranspose2d(dim_i,dim_o,kernel_size=up_size,stride=up_size)\n",
    "        self.attn_gate = AttentionGate(F_g=dim_i,F_x=dim_o,F_int=dim_o,pool_size=up_size)\n",
    "        \n",
    "        self.conv_r1 = nn.Conv2d(dim_i,dim_o,kernel_size=3,padding=\"same\")\n",
    "        self.conv_r2 = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "        \n",
    "        self.batchnorm_r1 = nn.BatchNorm2d(dim_o)\n",
    "        self.batchnorm_r2 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "    def forward(self,x,x_enc):\n",
    "        xi = self.trans_conv(x)\n",
    "        xa = self.attn_gate(x,x_enc)\n",
    "        xi = torch.cat((xi,xa),dim=1) #concatenating to the channel dimension\n",
    "        \n",
    "        xi = self.conv_r1(xi)\n",
    "        xi = F.leaky_relu(xi)\n",
    "        xi = self.batchnorm_r1(xi)\n",
    "        \n",
    "        xi = self.conv_r2(xi)\n",
    "        xi = F.leaky_relu(xi)\n",
    "        xi = self.batchnorm_r2(xi)\n",
    "        \n",
    "        return xi\n",
    "        \n",
    "\n",
    "\n",
    "class UNet_Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(UNet_Decoder,self).__init__()\n",
    "        \n",
    "        #since last two maxpools are x4, the filter and strides of first two transpose convs are 4 each\n",
    "        self.dec1 = DecoderBlock(1024,512,2)\n",
    "        self.dec2 = DecoderBlock(512,256,2)\n",
    "        self.dec3 = DecoderBlock(256,128,2)\n",
    "        self.dec4 = DecoderBlock(128,64,2)\n",
    "        self.dec5 = DecoderBlock(64,32,2)\n",
    "\n",
    "    \n",
    "    def forward(self,x1,x2,x3,x4,x5,x6): \n",
    "        xi = self.dec1(x6,x5)\n",
    "        xi = self.dec2(xi,x4)\n",
    "        xi = self.dec3(xi,x3)\n",
    "        xi = self.dec4(xi,x2)\n",
    "        xi = self.dec5(xi,x1)\n",
    "        \n",
    "        return xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xTNGGA9LkI1l"
   },
   "outputs": [],
   "source": [
    "#Input size is (window_size, 1, 512, 512)\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self,encoder,decoder):\n",
    "        super(UNet,self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.conv_f = nn.Conv2d(32,1,kernel_size=1)\n",
    "\n",
    "    def forward(self,x): #note: the entire batch is passed in \n",
    "\n",
    "        #Encoder\n",
    "        x1,x2,x3,x4,x5,x6 = self.encoder(x)\n",
    "\n",
    "        #Decoder\n",
    "        xi_1 = self.decoder(x1,x2,x3,x4,x5,x6)\n",
    "\n",
    "        #Final\n",
    "        xf = self.conv_f(xi_1)\n",
    "        xf = torch.sigmoid(xf)\n",
    "        return xf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86xxpPwE4P2W"
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nbDjUsNK4SFZ"
   },
   "outputs": [],
   "source": [
    "def log_dice_loss(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "    \n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    result = torch.log((2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth))\n",
    "    dice_loss = -1 * torch.sum(result)/y_pred.shape[0]\n",
    "    return  dice_loss\n",
    "\n",
    "def dice_loss(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "    \n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    result = (2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth)\n",
    "    dice_loss = torch.sum(1-result)/y_pred.shape[0]\n",
    "    return  dice_loss\n",
    "\n",
    "def focal_loss(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "\n",
    "#     #dice metric\n",
    "#     intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "#     result = (2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth)\n",
    "#     dice_loss = -1 * torch.sum(torch.log(result))\n",
    "\n",
    "    #focal loss\n",
    "    gamma = 2\n",
    "    alpha = 0.25\n",
    "\n",
    "    bce_loss = F.binary_cross_entropy_with_logits(y_pred_f,y_true_f,reduction='none')\n",
    "    pt = torch.exp(-1 * bce_loss)\n",
    "\n",
    "    temp_at = to_device(torch.tensor([alpha,1-alpha]),get_default_device())\n",
    "    y_true_f = y_true_f.type(torch.long)\n",
    "    at = ((1-alpha) * (1 - y_true_f)) + (alpha * y_true_f)\n",
    "\n",
    "    F_loss = torch.sum(at * ((1-pt) ** gamma) * bce_loss)\n",
    "\n",
    "    return  (F_loss) / y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmi9pVgX1H_4"
   },
   "source": [
    "## Eval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "y03p8HLy1L__"
   },
   "outputs": [],
   "source": [
    "#IOU [Between 0-1: Higher value => Better results]\n",
    "def iou_metric(y_pred,y_true):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "    \n",
    "    y_pred_f[y_pred_f >= 0.5] = 1\n",
    "    y_pred_f[y_pred_f < 0.5] = 0\n",
    "\n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    union = torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) - torch.sum(y_true_f * y_pred_f,1)\n",
    "    \n",
    "    iou_score = 0\n",
    "    for i in range(union.shape[0]):\n",
    "        if union[i] == 0:\n",
    "            iou_score += 1\n",
    "        else:\n",
    "            iou_score += intersection[i].item()/union[i].item()\n",
    "    iou_score = iou_score/y_pred.shape[0]\n",
    "    return iou_score\n",
    "\n",
    "#Dice [Between 0-1: Higher value => Better results]\n",
    "def dice_metric(y_pred,y_true):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "    \n",
    "    y_pred_f[y_pred_f >= 0.5] = 1\n",
    "    y_pred_f[y_pred_f < 0.5] = 0\n",
    "\n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    area_sum = torch.sum(y_true_f,1) + torch.sum(y_pred_f,1)\n",
    "    \n",
    "    dice_score = 0\n",
    "    for i in range(area_sum.shape[0]):\n",
    "        if area_sum[i] == 0:\n",
    "            dice_score += 1\n",
    "        else:\n",
    "            dice_score += 2. * intersection[i].item() / area_sum[i].item()\n",
    "    dice_score = dice_score/y_pred.shape[0]\n",
    "    return  dice_score\n",
    "\n",
    "#Precision [Between 0-1: Larger value => Better results]\n",
    "def precision_metric(y_pred,y_true):\n",
    "    y_true = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    tp = torch.sum(y_pred * y_true,1)\n",
    "    denom = torch.sum(y_pred,1)\n",
    "    true_sum = torch.sum(y_true,1)\n",
    "    \n",
    "    pre = 0\n",
    "    for i in range(denom.shape[0]):\n",
    "        if denom[i] == 0 and true_sum[i] == 0:\n",
    "            pre += 1\n",
    "        elif denom[i] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            pre += tp[i].item()/denom[i].item()\n",
    "    pre_score = pre/y_pred.shape[0]\n",
    "    return pre_score\n",
    "\n",
    "#Recall [Between 0-1: Larger value => Better results]\n",
    "def recall_metric(y_pred,y_true):\n",
    "    y_true = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    tp = torch.sum(y_pred * y_true,1)\n",
    "    denom = torch.sum(y_true,1)\n",
    "    \n",
    "    re = 0\n",
    "    for i in range(denom.shape[0]):\n",
    "        if denom[i] == 0:\n",
    "            re += 1\n",
    "        else:\n",
    "            re += tp[i].item()/denom[i].item()\n",
    "    re_score = re/y_pred.shape[0]\n",
    "    return re_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-kEzBmcfvXT"
   },
   "source": [
    "## Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "REi6xcXTfu5H"
   },
   "outputs": [],
   "source": [
    "def eval(model,test_df,img_size,seg_organ,batch_size,epoch=0,epochs=0):\n",
    "    #epoch and epoch size is passed if this function is called during training in between epochs\n",
    "    model.eval()\n",
    "    test_dataloader = Datagen_CT(df=test_df,img_size=img_size,seg_organ=seg_organ,batch_size=batch_size)\n",
    "\n",
    "    iou_val = 0\n",
    "    dice_val = 0\n",
    "    pre_val = 0\n",
    "    re_val = 0\n",
    "\n",
    "    count = 0\n",
    "    for batch_idx, (X,y) in enumerate(test_dataloader):\n",
    "        X = to_device(torch.tensor(X, requires_grad=True),get_default_device())\n",
    "        y = to_device(torch.tensor(y, requires_grad=True),get_default_device())\n",
    "\n",
    "        output = model(X)\n",
    "        iou_val += iou_metric(output,y)\n",
    "        dice_val += dice_metric(output,y)\n",
    "        pre_val += precision_metric(output,y)\n",
    "        re_val += recall_metric(output,y)\n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    dice_score = dice_val/count\n",
    "    iou_score = iou_val/count\n",
    "    pre_score = pre_val/count\n",
    "    re_score = re_val/count\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('End of Epoch [{}/{}]   Dice Metric: {:.4f}  IoU Metric: {:.4f}  Precision Metric: {:.4f}  Recall Metric: {:.4f}'.format(epoch+1,epochs,dice_score,iou_score,pre_score,re_score))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u66Hwr_H6Tcq"
   },
   "source": [
    "## Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6FHKWuS97dEa"
   },
   "outputs": [],
   "source": [
    "def fit(model,img_size,seg_organ,batch_size,loss_fn,optimizer,scheduler,epochs,train_df,test_df,validate=False,print_every=1):\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        train_dataloader = Datagen_CT(df=train_df,img_size=img_size,seg_organ=seg_organ,batch_size=batch_size)\n",
    "        \n",
    "        total_loss = 0\n",
    "        max_out = 0\n",
    "        for batch_idx, (X,y) in enumerate(train_dataloader):\n",
    "            X = to_device(torch.tensor(X, requires_grad=True),get_default_device())\n",
    "            y = to_device(torch.tensor(y, requires_grad=True),get_default_device())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            loss = loss_fn(output,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            max_out = max(max_out,torch.max(output))\n",
    "\n",
    "            if batch_idx != 0 and batch_idx % print_every == 0:\n",
    "                print('Epoch [{}/{}]   Batch {}   Loss: {:.4f}    Max: {:.4f}'.format(epoch+1,epochs,batch_idx,total_loss/print_every,max_out))\n",
    "                total_loss = 0\n",
    "                max_out = 0\n",
    "        \n",
    "\n",
    "#                 plt.subplot(1,3,1)\n",
    "#                 plt.imshow(X.cpu().detach().numpy()[0][0])\n",
    "\n",
    "#                 plt.subplot(1,3,2)\n",
    "#                 plt.imshow(y.cpu().detach().numpy()[0][0])\n",
    "\n",
    "#                 plt.subplot(1,3,3)\n",
    "#                 plt.imshow(output.cpu().detach().numpy()[0][0])\n",
    "\n",
    "#                 plt.show()\n",
    "\n",
    "\n",
    "#         print('Epoch [{}/{}]   Batch {}   Loss: {:.4f}    lr: {:.10f}'.format(epoch+1,epochs,batch_idx,loss.item(),optimizer.param_groups[0]['lr']))\n",
    "#         print('\\n')\n",
    "        scheduler.step()\n",
    "\n",
    "        if validate:\n",
    "            eval(model=model,test_df=test_df,img_size=img_size,seg_organ=seg_organ,batch_size=batch_size,epoch=epoch,epochs=epochs)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zssyz5Jb7lUS"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "T27vlfDj6Rvk"
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "img_size = 512\n",
    "epochs = 100\n",
    "seg_organ = 'Lung_L'\n",
    "train_test_split = 0.8\n",
    "batch_size = 5\n",
    "\n",
    "#Dataset Specific\n",
    "train_df = df[:int(train_test_split*df.shape[0])].reset_index(drop=True)\n",
    "test_df = df[int(train_test_split*df.shape[0]):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "C06Rfn3_RlWi"
   },
   "outputs": [],
   "source": [
    "#Model Specific\n",
    "enc = UNet_Encoder()\n",
    "dec = UNet_Decoder()\n",
    "model = UNet(enc,dec)\n",
    "model = to_device(model,get_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZWCAg4TSRlWi",
    "outputId": "53f25b29-1634-4f16-eeb3-07a71b7dfd2f"
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('Adv_MSA_wAG_Model/v1'))\n",
    "#'/content/drive/MyDrive/AI Club Project - Segmentation/UNet - Models/Single Slice Models/adv_sma_wag_lung_l_100epochs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "w-TbgiPdRlWi"
   },
   "outputs": [],
   "source": [
    "#Training Specific\n",
    "loss_fn = dice_loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[], gamma=0.1)#7#11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "id": "6FXFZK03-l1_",
    "outputId": "8e37ab82-8784-4bc8-ce47-91cdc47bdc42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LR:  0.001\n",
      "\n",
      "\n",
      "End of Epoch [1/100]   Dice Metric: 0.4891  IoU Metric: 0.4250  Precision Metric: 0.4260  Recall Metric: 0.9974\n",
      "End of Epoch [2/100]   Dice Metric: 0.5519  IoU Metric: 0.5124  Precision Metric: 0.5232  Recall Metric: 0.9785\n",
      "End of Epoch [3/100]   Dice Metric: 0.5405  IoU Metric: 0.4921  Precision Metric: 0.5403  Recall Metric: 0.9427\n",
      "End of Epoch [4/100]   Dice Metric: 0.5804  IoU Metric: 0.5441  Precision Metric: 0.5538  Recall Metric: 0.9799\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2569/1235017119.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m fit(model=model, img_size=img_size, seg_organ=seg_organ, batch_size=batch_size,\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2569/2393725515.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, img_size, seg_organ, batch_size, loss_fn, optimizer, scheduler, epochs, train_df, test_df, validate, print_every)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting LR: \",0.001)\n",
    "print('\\n')\n",
    "\n",
    "fit(model=model, img_size=img_size, seg_organ=seg_organ, batch_size=batch_size,\n",
    "    loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler,\n",
    "    epochs=epochs, train_df=train_df, test_df=test_df, \n",
    "    validate=True, print_every=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3pzpl8BRlWi"
   },
   "outputs": [],
   "source": [
    "eval(model=model,test_df=test_df,img_size=img_size,seg_organ=seg_organ,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "3opZPVo6Ipsm"
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(),'Adv_MSA_wAG_Model/v1' )\n",
    "#'/content/drive/MyDrive/AI Club Project - Segmentation/UNet - Models/Single Slice Models/adv_sma_wag_lung_l_100epochs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCdmqFEgwizO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9teq9wX-OV6h"
   ],
   "name": "Adv_UNet_wAG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
