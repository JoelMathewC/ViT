{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAF5Ck2mRlWU",
    "outputId": "8601c14d-e805-41d9-87db-d0c4ca045c66"
   },
   "outputs": [],
   "source": [
    "#!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_ZEBu_751r_"
   },
   "outputs": [],
   "source": [
    "#This is so that the plots are there along with the code in the notebook rather than a popup\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os.path import isfile,join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import torchvision.transforms as T\n",
    "from torch.nn.modules import padding\n",
    "# from scipy.ndimage import distance_transform_edt\n",
    "# from monai.metrics import HausdorffDistanceMetric,SurfaceDistanceMetric\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PMNVCoWIOFrH"
   },
   "outputs": [],
   "source": [
    "# For reproducing results\n",
    "seed = 48\n",
    "#random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fv36BQj_RnXf",
    "outputId": "fed381ed-7380-4eaf-c917-9e9ae8ff6589"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzlbX_g4MKfj"
   },
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZjV8W8y19pJi"
   },
   "outputs": [],
   "source": [
    "# GPU | CPU\n",
    "def get_default_device():\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda:1')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data,device):\n",
    "    \n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    \n",
    "    return data.to(device,non_blocking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uXSjyGJ84VwK"
   },
   "outputs": [],
   "source": [
    "''' ----------------------------------------------------------\n",
    "    All the content here is intermediate data used to obtain df\n",
    "    None of these will be referenced later in the notebook \n",
    "    ---------------------------------------------------------- '''\n",
    "\n",
    "base_path = \"../processed/\"\n",
    "#\"../processed/\"\n",
    "#\"/content/drive/MyDrive/AI Club Project - Segmentation/processed/\"\n",
    "\n",
    "file_names = {\"image\": \"img_crp_v2.npy\", \n",
    "              \"esophagus\": \"structure/Esophagus_crp_v2.npy\",\n",
    "              \"heart\": \"structure/Heart_crp_v2.npy\",\n",
    "              \"lung_L\": \"structure/Lung_L_crp_v2.npy\",\n",
    "              \"lung_R\": \"structure/Lung_R_crp_v2.npy\",\n",
    "              \"spinal_cord\": \"structure/SpinalCord_crp_v2.npy\"} \n",
    "\n",
    "train_dirs = [(base_path + f + \"/\") for f in os.listdir(base_path) if not isfile(join(base_path,f)) and 'Test' not in f]\n",
    "\n",
    "val_dirs = [(base_path + f + \"/\") for f in ['LCTSC-Test-S1-104/','LCTSC-Test-S1-101/','LCTSC-Test-S2-103/',\n",
    "             'LCTSC-Test-S1-102/','LCTSC-Test-S3-104/','LCTSC-Test-S3-103/',\n",
    "             'LCTSC-Test-S1-103/','LCTSC-Test-S2-102/','LCTSC-Test-S3-101/',\n",
    "             'LCTSC-Test-S3-102/','LCTSC-Test-S2-104/','LCTSC-Test-S2-101/']]\n",
    "\n",
    "test_dirs = [(base_path + f + \"/\") for f in ['LCTSC-Test-S1-204/','LCTSC-Test-S1-202/','LCTSC-Test-S3-202/',\n",
    "             'LCTSC-Test-S2-204/','LCTSC-Test-S2-202/','LCTSC-Test-S2-201/',\n",
    "             'LCTSC-Test-S2-203/','LCTSC-Test-S1-203/','LCTSC-Test-S3-201/',\n",
    "             'LCTSC-Test-S3-203/','LCTSC-Test-S3-204/','LCTSC-Test-S1-201/']]\n",
    "\n",
    "\n",
    "data_train = [[f + file_names[\"image\"],\n",
    "         f + file_names[\"esophagus\"],\n",
    "         f + file_names[\"heart\"],\n",
    "         f + file_names[\"lung_L\"],\n",
    "         f + file_names[\"lung_R\"],\n",
    "         f + file_names[\"spinal_cord\"]] for f in train_dirs]\n",
    "\n",
    "data_val = [[f + file_names[\"image\"],\n",
    "         f + file_names[\"esophagus\"],\n",
    "         f + file_names[\"heart\"],\n",
    "         f + file_names[\"lung_L\"],\n",
    "         f + file_names[\"lung_R\"],\n",
    "         f + file_names[\"spinal_cord\"]] for f in val_dirs]\n",
    "\n",
    "data_train = data_train.append(data_val)\n",
    "\n",
    "data_test = [[f + file_names[\"image\"],\n",
    "         f + file_names[\"esophagus\"],\n",
    "         f + file_names[\"heart\"],\n",
    "         f + file_names[\"lung_L\"],\n",
    "         f + file_names[\"lung_R\"],\n",
    "         f + file_names[\"spinal_cord\"]] for f in test_dirs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "lk_bn5ERlib4",
    "outputId": "dc6358c4-e9bf-43ed-f5d2-2e6cd14aae7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Esophagus</th>\n",
       "      <th>Heart</th>\n",
       "      <th>Lung_L</th>\n",
       "      <th>Lung_R</th>\n",
       "      <th>SpinalCord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../processed/LCTSC-Train-S3-005/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005/structure/Esop...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005/structure/Hear...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005/structure/Spin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../processed/LCTSC-Train-S1-004/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004/structure/Esop...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004/structure/Hear...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004/structure/Spin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../processed/LCTSC-Train-S2-004/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004/structure/Esop...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004/structure/Hear...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004/structure/Spin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../processed/LCTSC-Train-S3-008/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008/structure/Esop...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008/structure/Hear...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008/structure/Spin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../processed/LCTSC-Train-S3-012/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012/structure/Esop...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012/structure/Hear...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012/structure/Spin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Image  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/img_crp_v2.npy   \n",
       "1  ../processed/LCTSC-Train-S1-004/img_crp_v2.npy   \n",
       "2  ../processed/LCTSC-Train-S2-004/img_crp_v2.npy   \n",
       "3  ../processed/LCTSC-Train-S3-008/img_crp_v2.npy   \n",
       "4  ../processed/LCTSC-Train-S3-012/img_crp_v2.npy   \n",
       "\n",
       "                                           Esophagus  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/structure/Esop...   \n",
       "1  ../processed/LCTSC-Train-S1-004/structure/Esop...   \n",
       "2  ../processed/LCTSC-Train-S2-004/structure/Esop...   \n",
       "3  ../processed/LCTSC-Train-S3-008/structure/Esop...   \n",
       "4  ../processed/LCTSC-Train-S3-012/structure/Esop...   \n",
       "\n",
       "                                               Heart  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/structure/Hear...   \n",
       "1  ../processed/LCTSC-Train-S1-004/structure/Hear...   \n",
       "2  ../processed/LCTSC-Train-S2-004/structure/Hear...   \n",
       "3  ../processed/LCTSC-Train-S3-008/structure/Hear...   \n",
       "4  ../processed/LCTSC-Train-S3-012/structure/Hear...   \n",
       "\n",
       "                                              Lung_L  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/structure/Lung...   \n",
       "1  ../processed/LCTSC-Train-S1-004/structure/Lung...   \n",
       "2  ../processed/LCTSC-Train-S2-004/structure/Lung...   \n",
       "3  ../processed/LCTSC-Train-S3-008/structure/Lung...   \n",
       "4  ../processed/LCTSC-Train-S3-012/structure/Lung...   \n",
       "\n",
       "                                              Lung_R  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/structure/Lung...   \n",
       "1  ../processed/LCTSC-Train-S1-004/structure/Lung...   \n",
       "2  ../processed/LCTSC-Train-S2-004/structure/Lung...   \n",
       "3  ../processed/LCTSC-Train-S3-008/structure/Lung...   \n",
       "4  ../processed/LCTSC-Train-S3-012/structure/Lung...   \n",
       "\n",
       "                                          SpinalCord  \n",
       "0  ../processed/LCTSC-Train-S3-005/structure/Spin...  \n",
       "1  ../processed/LCTSC-Train-S1-004/structure/Spin...  \n",
       "2  ../processed/LCTSC-Train-S2-004/structure/Spin...  \n",
       "3  ../processed/LCTSC-Train-S3-008/structure/Spin...  \n",
       "4  ../processed/LCTSC-Train-S3-012/structure/Spin...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df contains all data regarding input data\n",
    "df_train = pd.DataFrame(data_train, columns = ['Image','Esophagus','Heart','Lung_L','Lung_R','SpinalCord'])\n",
    "df_test = pd.DataFrame(data_test, columns = ['Image','Esophagus','Heart','Lung_L','Lung_R','SpinalCord'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtY6RXHnCvdK"
   },
   "source": [
    "## Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KHCzYFLMyfHs"
   },
   "outputs": [],
   "source": [
    "def Datagen_CT(df,img_size,seg_organ,batch_size):\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        image = np.load(row[\"Image\"])\n",
    "        image = np.moveaxis(image,0,-1)\n",
    "        image = cv2.resize(image, (img_size,img_size))\n",
    "        image = np.swapaxes(image,0,-1)\n",
    "\n",
    "        mask = np.load(row[seg_organ])\n",
    "        mask = np.moveaxis(mask,0,-1)\n",
    "        mask = cv2.resize(mask , (img_size,img_size))\n",
    "        mask = np.swapaxes(mask,0,-1)\n",
    "        \n",
    "        slice_index = 0 #the index of the next slice to be examined\n",
    "\n",
    "        while slice_index < image.shape[0]:#we put mask here because image has a longer size to adjust for the last slice\n",
    "            images = image[slice_index: slice_index + batch_size,:,:]\n",
    "            masks = mask[slice_index: slice_index + batch_size,:,:]\n",
    "\n",
    "            slice_index = slice_index + batch_size\n",
    "            images = np.expand_dims(images,axis=1).astype('float32')\n",
    "            masks = np.expand_dims(masks,axis=1).astype('float32')\n",
    "\n",
    "            yield images, masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVmUybur4BHq"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fTZ8r4G-RlWd"
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim_i,dim_o):\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(dim_i,dim_o,3,padding=\"same\")\n",
    "        self.batchnorm1 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(dim_o,dim_o,3,padding=\"same\")\n",
    "        self.batchnorm2 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(dim_o,dim_o,3,padding=\"same\")\n",
    "        self.batchnorm3 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.batchnorm1(x1)\n",
    "        x1 = F.leaky_relu(x1)\n",
    "        \n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.batchnorm2(x2)\n",
    "        x2 = F.leaky_relu(x2)\n",
    "        \n",
    "        x3 = self.conv2(x2)\n",
    "        x3 = self.batchnorm2(x3)\n",
    "        x3 = x3 + x1\n",
    "        x3 = F.leaky_relu(x3)\n",
    "        return x3\n",
    "\n",
    "class UNet_Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(UNet_Encoder,self).__init__()\n",
    "\n",
    "        self.enc1 = EncoderBlock(1,32)\n",
    "        self.enc2 = EncoderBlock(32,64)\n",
    "        self.enc3 = EncoderBlock(64,128)\n",
    "        self.enc4 = EncoderBlock(128,256)\n",
    "        self.enc5 = EncoderBlock(256,512)\n",
    "        self.enc6 = EncoderBlock(512,1024)\n",
    "  \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        x1 = self.enc1(x)\n",
    "        \n",
    "        x2 = self.maxpool(x1)\n",
    "        x2 = self.enc2(x2)\n",
    "        \n",
    "        x3 = self.maxpool(x2)\n",
    "        x3 = self.enc3(x3)\n",
    "\n",
    "        x4 = self.maxpool(x3)\n",
    "        x4 = self.enc4(x4)\n",
    "\n",
    "        x5 = self.maxpool(x4)\n",
    "        x5 = self.enc5(x5)\n",
    "\n",
    "        x6 = self.maxpool(x5)\n",
    "        x6 = self.enc6(x6)\n",
    "        \n",
    "        return (x1,x2,x3,x4,x5,x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RZ3-n4plRlWe"
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim_i,dim_o,up_size):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        \n",
    "        self.trans_conv = nn.ConvTranspose2d(dim_i,dim_o,kernel_size=up_size,stride=up_size)\n",
    "        \n",
    "        self.conv_r1 = nn.Conv2d(dim_i,dim_o,kernel_size=3,padding=\"same\")\n",
    "        self.conv_r2 = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "        self.conv_r3 = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "        \n",
    "        self.batchnorm_r1 = nn.BatchNorm2d(dim_o)\n",
    "        self.batchnorm_r2 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "    def forward(self,x,x_enc):\n",
    "        xi = self.trans_conv(x)\n",
    "        xi = torch.cat((xi,x_enc),dim=1) #concatenating to the channel dimension\n",
    "        \n",
    "        x1 = self.conv_r1(xi)\n",
    "        x1 = self.batchnorm_r1(x1)\n",
    "        x1 = F.leaky_relu(x1)\n",
    "        \n",
    "        x2 = self.conv_r2(x1)\n",
    "        x2 = self.batchnorm_r2(x2)\n",
    "        x2 = F.leaky_relu(x2)\n",
    "        \n",
    "        x3 = self.conv_r3(x2)\n",
    "        x3 = self.batchnorm_r2(x3)\n",
    "        x3 = x3 + x1\n",
    "        x3 = F.leaky_relu(x3)\n",
    "        \n",
    "        return x3\n",
    "        \n",
    "\n",
    "\n",
    "class UNet_Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(UNet_Decoder,self).__init__()\n",
    "        \n",
    "        #since last two maxpools are x4, the filter and strides of first two transpose convs are 4 each\n",
    "        self.dec1 = DecoderBlock(1024,512,4)\n",
    "        self.dec2 = DecoderBlock(512,256,4)\n",
    "        self.dec3 = DecoderBlock(256,128,2)\n",
    "        self.dec4 = DecoderBlock(128,64,2)\n",
    "        self.dec5 = DecoderBlock(64,32,2)\n",
    "\n",
    "    \n",
    "    def forward(self,x1,x2,x3,x4,x5,x6): \n",
    "        xi = self.dec1(x6,x5)\n",
    "        xi = self.dec2(xi,x4)\n",
    "        xi = self.dec3(xi,x3)\n",
    "        xi = self.dec4(xi,x2)\n",
    "        xi = self.dec5(xi,x1)\n",
    "        \n",
    "        return xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xTNGGA9LkI1l"
   },
   "outputs": [],
   "source": [
    "#Input size is (window_size, 1, 512, 512)\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self,encoder,decoder):\n",
    "        super(UNet,self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.conv_f = nn.Conv2d(32,1,kernel_size=1)\n",
    "\n",
    "    def forward(self,x): #note: the entire batch is passed in \n",
    "\n",
    "        #Encoder\n",
    "        x1,x2,x3,x4,x5,x6 = self.encoder(x)\n",
    "\n",
    "        #Decoder\n",
    "        xi_1 = self.decoder(x1,x2,x3,x4,x5,x6)\n",
    "\n",
    "        #Final\n",
    "        xf = self.conv_f(xi_1)\n",
    "        xf = torch.sigmoid(xf)\n",
    "        return xf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86xxpPwE4P2W"
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nbDjUsNK4SFZ"
   },
   "outputs": [],
   "source": [
    "def log_dice_loss(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "    \n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    result = torch.log((2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth))\n",
    "    dice_loss = -1 * torch.sum(result)/y_pred.shape[0]\n",
    "    return  dice_loss\n",
    "\n",
    "def dice_loss(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "    \n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    result = (2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth)\n",
    "    dice_loss = torch.sum(1-result)/y_pred.shape[0]\n",
    "    return  dice_loss\n",
    "\n",
    "def focal_loss(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "\n",
    "#     #dice metric\n",
    "#     intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "#     result = (2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth)\n",
    "#     dice_loss = -1 * torch.sum(torch.log(result))\n",
    "\n",
    "    #focal loss\n",
    "    gamma = 2\n",
    "    alpha = 0.25\n",
    "\n",
    "    bce_loss = F.binary_cross_entropy_with_logits(y_pred_f,y_true_f,reduction='none')\n",
    "    pt = torch.exp(-1 * bce_loss)\n",
    "\n",
    "    temp_at = to_device(torch.tensor([alpha,1-alpha]),get_default_device())\n",
    "    y_true_f = y_true_f.type(torch.long)\n",
    "    at = ((1-alpha) * (1 - y_true_f)) + (alpha * y_true_f)\n",
    "\n",
    "    F_loss = torch.sum(at * ((1-pt) ** gamma) * bce_loss)\n",
    "\n",
    "    return  (F_loss) / y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmi9pVgX1H_4"
   },
   "source": [
    "## Eval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "y03p8HLy1L__"
   },
   "outputs": [],
   "source": [
    "#IOU [Between 0-1: Higher value => Better results]\n",
    "def iou_metric(y_pred,y_true):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "    \n",
    "    y_pred_f[y_pred_f >= 0.5] = 1\n",
    "    y_pred_f[y_pred_f < 0.5] = 0\n",
    "\n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    union = torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) - torch.sum(y_true_f * y_pred_f,1)\n",
    "    \n",
    "    iou_score = 0\n",
    "    for i in range(union.shape[0]):\n",
    "        if union[i] == 0:\n",
    "            iou_score += 1\n",
    "        else:\n",
    "            iou_score += intersection[i].item()/union[i].item()\n",
    "    iou_score = iou_score/y_pred.shape[0]\n",
    "    return iou_score\n",
    "\n",
    "#Dice [Between 0-1: Higher value => Better results]\n",
    "def dice_metric(y_pred,y_true):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "    \n",
    "    y_pred_f[y_pred_f >= 0.5] = 1\n",
    "    y_pred_f[y_pred_f < 0.5] = 0\n",
    "\n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    area_sum = torch.sum(y_true_f,1) + torch.sum(y_pred_f,1)\n",
    "    \n",
    "    dice_score = 0\n",
    "    for i in range(area_sum.shape[0]):\n",
    "        if area_sum[i] == 0:\n",
    "            dice_score += 1\n",
    "        else:\n",
    "            dice_score += 2. * intersection[i].item() / area_sum[i].item()\n",
    "    dice_score = dice_score/y_pred.shape[0]\n",
    "    return  dice_score\n",
    "\n",
    "#Precision [Between 0-1: Larger value => Better results]\n",
    "def precision_metric(y_pred,y_true):\n",
    "    y_true = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    tp = torch.sum(y_pred * y_true,1)\n",
    "    denom = torch.sum(y_pred,1)\n",
    "    true_sum = torch.sum(y_true,1)\n",
    "    \n",
    "    pre = 0\n",
    "    for i in range(denom.shape[0]):\n",
    "        if denom[i] == 0 and true_sum[i] == 0:\n",
    "            pre += 1\n",
    "        elif denom[i] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            pre += tp[i].item()/denom[i].item()\n",
    "    pre_score = pre/y_pred.shape[0]\n",
    "    return pre_score\n",
    "\n",
    "#Recall [Between 0-1: Larger value => Better results]\n",
    "def recall_metric(y_pred,y_true):\n",
    "    y_true = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    tp = torch.sum(y_pred * y_true,1)\n",
    "    denom = torch.sum(y_true,1)\n",
    "    \n",
    "    re = 0\n",
    "    for i in range(denom.shape[0]):\n",
    "        if denom[i] == 0:\n",
    "            re += 1\n",
    "        else:\n",
    "            re += tp[i].item()/denom[i].item()\n",
    "    re_score = re/y_pred.shape[0]\n",
    "    return re_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-kEzBmcfvXT"
   },
   "source": [
    "## Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "REi6xcXTfu5H"
   },
   "outputs": [],
   "source": [
    "def eval(model,val_df,img_size,seg_organ,batch_size,epoch=0,epochs=0):\n",
    "    #epoch and epoch size is passed if this function is called during training in between epochs\n",
    "    model.eval()\n",
    "    test_dataloader = Datagen_CT(df=val_df,img_size=img_size,seg_organ=seg_organ,batch_size=batch_size)\n",
    "\n",
    "    iou_val = 0\n",
    "    dice_val = 0\n",
    "    pre_val = 0\n",
    "    re_val = 0\n",
    "\n",
    "    count = 0\n",
    "    for batch_idx, (X,y) in enumerate(test_dataloader):\n",
    "        X = to_device(torch.tensor(X, requires_grad=True),get_default_device())\n",
    "        y = to_device(torch.tensor(y, requires_grad=True),get_default_device())\n",
    "\n",
    "        output = model(X)\n",
    "        iou_val += iou_metric(output,y)\n",
    "        dice_val += dice_metric(output,y)\n",
    "        pre_val += precision_metric(output,y)\n",
    "        re_val += recall_metric(output,y)\n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    dice_score = dice_val/count\n",
    "    iou_score = iou_val/count\n",
    "    pre_score = pre_val/count\n",
    "    re_score = re_val/count\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('End of Epoch [{}/{}]   Dice Metric: {:.4f}  IoU Metric: {:.4f}  Precision Metric: {:.4f}  Recall Metric: {:.4f}'.format(epoch+1,epochs,dice_score,iou_score,pre_score,re_score))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u66Hwr_H6Tcq"
   },
   "source": [
    "## Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6FHKWuS97dEa"
   },
   "outputs": [],
   "source": [
    "def fit(model,img_size,seg_organ,batch_size,loss_fn,optimizer,scheduler,epochs,train_df,val_df,validate=False,print_every=1):\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        train_dataloader = Datagen_CT(df=train_df,img_size=img_size,seg_organ=seg_organ,batch_size=batch_size)\n",
    "        \n",
    "        total_loss = 0\n",
    "        max_out = 0\n",
    "        for batch_idx, (X,y) in enumerate(train_dataloader):\n",
    "            X = to_device(torch.tensor(X, requires_grad=True),get_default_device())\n",
    "            y = to_device(torch.tensor(y, requires_grad=True),get_default_device())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            loss = loss_fn(output,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            max_out = max(max_out,torch.max(output))\n",
    "\n",
    "            if batch_idx != 0 and batch_idx % print_every == 0:\n",
    "                print('Epoch [{}/{}]   Batch {}   Loss: {:.4f}    Max: {:.4f}'.format(epoch+1,epochs,batch_idx,total_loss/print_every,max_out))\n",
    "                total_loss = 0\n",
    "                max_out = 0\n",
    "        \n",
    "\n",
    "#                 plt.subplot(1,3,1)\n",
    "#                 plt.imshow(X.cpu().detach().numpy()[0][0])\n",
    "\n",
    "#                 plt.subplot(1,3,2)\n",
    "#                 plt.imshow(y.cpu().detach().numpy()[0][0])\n",
    "\n",
    "#                 plt.subplot(1,3,3)\n",
    "#                 plt.imshow(output.cpu().detach().numpy()[0][0])\n",
    "\n",
    "#                 plt.show()\n",
    "\n",
    "\n",
    "#         print('Epoch [{}/{}]   Batch {}   Loss: {:.4f}    lr: {:.10f}'.format(epoch+1,epochs,batch_idx,loss.item(),optimizer.param_groups[0]['lr']))\n",
    "#         print('\\n')\n",
    "        scheduler.step()\n",
    "\n",
    "        if validate:\n",
    "            eval(model=model,val_df=val_df,img_size=img_size,seg_organ=seg_organ,batch_size=batch_size,epoch=epoch,epochs=epochs)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zssyz5Jb7lUS"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "T27vlfDj6Rvk"
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "img_size = 512\n",
    "epochs = 100\n",
    "seg_organ = 'Lung_L'\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "C06Rfn3_RlWi"
   },
   "outputs": [],
   "source": [
    "#Model Specific\n",
    "enc = UNet_Encoder()\n",
    "dec = UNet_Decoder()\n",
    "model = UNet(enc,dec)\n",
    "model = to_device(model,get_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZWCAg4TSRlWi"
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('Adv_MSA_wAG_Model/v1'))\n",
    "#'/content/drive/MyDrive/AI Club Project - Segmentation/UNet - Models/Single Slice Models/adv_sma_wag_lung_l_100epochs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "w-TbgiPdRlWi"
   },
   "outputs": [],
   "source": [
    "#Training Specific\n",
    "loss_fn = dice_loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "6FXFZK03-l1_",
    "outputId": "5b0908a2-5229-4c13-a8f0-855b89e22151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LR:  0.001\n",
      "\n",
      "\n",
      "End of Epoch [1/100]   Dice Metric: 0.4194  IoU Metric: 0.3091  Precision Metric: 0.3289  Recall Metric: 0.9283\n",
      "End of Epoch [2/100]   Dice Metric: 0.3871  IoU Metric: 0.2781  Precision Metric: 0.3037  Recall Metric: 0.8912\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3008/264044927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m fit(model=model, img_size=img_size, seg_organ=seg_organ, batch_size=batch_size,\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3008/319369285.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, img_size, seg_organ, batch_size, loss_fn, optimizer, scheduler, epochs, train_df, val_df, validate, print_every)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseg_organ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseg_organ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3008/1212684983.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, val_df, img_size, seg_organ, batch_size, epoch, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0miou_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0miou_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdice_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdice_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpre_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprecision_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mre_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrecall_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3008/649841286.py\u001b[0m in \u001b[0;36mprecision_metric\u001b[0;34m(y_pred, y_true)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(model=model, img_size=img_size, seg_organ=seg_organ, batch_size=batch_size,\n",
    "    loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler,\n",
    "    epochs=epochs, train_df=df_train, val_df=df_test, \n",
    "    validate=True, print_every=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3pzpl8BRlWi"
   },
   "outputs": [],
   "source": [
    "eval(model=model,val_df=df_test,img_size=img_size,seg_organ=seg_organ,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3opZPVo6Ipsm"
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(),'Adv_MSA_wAG_Model/v1' )\n",
    "#'/content/drive/MyDrive/AI Club Project - Segmentation/UNet - Models/Single Slice Models/adv_sma_wag_lung_l_100epochs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCdmqFEgwizO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Conventional UNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
