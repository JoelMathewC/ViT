{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRdAmOSZKa05",
    "outputId": "31edac67-de16-43ef-bd06-e92a214926bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Collecting tokenizers!=0.11.3,>=0.10.1\n",
      "  Downloading tokenizers-0.11.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 329 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.3.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.4.0 tokenizers-0.11.4 transformers-4.16.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hfTL1ewIFZ_k"
   },
   "outputs": [],
   "source": [
    "#This is so that the plots are there along with the code in the notebook rather than a popup\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os.path import isfile,join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import torchvision.transforms as T\n",
    "from torch.nn.modules import padding\n",
    "import math\n",
    "import sys\n",
    "from transformers import ViTModel, ViTConfig, ViTFeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7e4W6ImKksa"
   },
   "source": [
    "## Starting Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "h0zwACnsHcDd"
   },
   "outputs": [],
   "source": [
    "# For reproducing results\n",
    "seed = 48\n",
    "#random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hXRcilhhHnxb"
   },
   "outputs": [],
   "source": [
    "# GPU | CPU\n",
    "def get_default_device():\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda:0')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data,device):\n",
    "    \n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    \n",
    "    return data.to(device,non_blocking = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt-6E-XpHhY5"
   },
   "source": [
    "## Getting Data (Verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pcBB5HloHeNu",
    "outputId": "c61fec3b-d124-4495-e49c-324710eabce9"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_7KDRo6sHk2T"
   },
   "outputs": [],
   "source": [
    "''' ----------------------------------------------------------\n",
    "    All the content here is intermediate data used to obtain df\n",
    "    None of these will be referenced later in the notebook \n",
    "    ---------------------------------------------------------- '''\n",
    "\n",
    "base_path = \"../processed/\"\n",
    "#\"../processed/\"\n",
    "#\"/content/drive/MyDrive/AI Club Project - Segmentation/processed/\"\n",
    "\n",
    "file_names = {\"image\": \"img_crp_v2.npy\", \n",
    "              \"esophagus\": \"structure/Esophagus_crp_v2.npy\",\n",
    "              \"heart\": \"structure/Heart_crp_v2.npy\",\n",
    "              \"lung_L\": \"structure/Lung_L_crp_v2.npy\",\n",
    "              \"lung_R\": \"structure/Lung_R_crp_v2.npy\",\n",
    "              \"spinal_cord\": \"structure/SpinalCord_crp_v2.npy\"} \n",
    "\n",
    "train_dirs = [(base_path + f + \"/\") for f in os.listdir(base_path) if not isfile(join(base_path,f)) and 'Test' not in f]\n",
    "\n",
    "val_dirs = [(base_path + f + \"/\") for f in ['LCTSC-Test-S1-104','LCTSC-Test-S1-101','LCTSC-Test-S2-103',\n",
    "             'LCTSC-Test-S1-102','LCTSC-Test-S3-104','LCTSC-Test-S3-103',\n",
    "             'LCTSC-Test-S1-103','LCTSC-Test-S2-102','LCTSC-Test-S3-101',\n",
    "             'LCTSC-Test-S3-102','LCTSC-Test-S2-104','LCTSC-Test-S2-101']]\n",
    "\n",
    "test_dirs = [(base_path + f + \"/\") for f in ['LCTSC-Test-S1-204','LCTSC-Test-S1-202','LCTSC-Test-S3-202',\n",
    "             'LCTSC-Test-S2-204','LCTSC-Test-S2-202','LCTSC-Test-S2-201',\n",
    "             'LCTSC-Test-S2-203','LCTSC-Test-S1-203','LCTSC-Test-S3-201',\n",
    "             'LCTSC-Test-S3-203','LCTSC-Test-S3-204','LCTSC-Test-S1-201']]\n",
    "\n",
    "\n",
    "data_train = [[f + file_names[\"image\"],\n",
    "         f + file_names[\"esophagus\"],\n",
    "         f + file_names[\"heart\"],\n",
    "         f + file_names[\"lung_L\"],\n",
    "         f + file_names[\"lung_R\"],\n",
    "         f + file_names[\"spinal_cord\"]] for f in train_dirs]\n",
    "\n",
    "data_val = [[f + file_names[\"image\"],\n",
    "         f + file_names[\"esophagus\"],\n",
    "         f + file_names[\"heart\"],\n",
    "         f + file_names[\"lung_L\"],\n",
    "         f + file_names[\"lung_R\"],\n",
    "         f + file_names[\"spinal_cord\"]] for f in val_dirs]\n",
    "\n",
    "# for arr in data_val:\n",
    "#     data_train.append(arr)\n",
    "\n",
    "data_test = [[f + file_names[\"image\"],\n",
    "         f + file_names[\"esophagus\"],\n",
    "         f + file_names[\"heart\"],\n",
    "         f + file_names[\"lung_L\"],\n",
    "         f + file_names[\"lung_R\"],\n",
    "         f + file_names[\"spinal_cord\"]] for f in test_dirs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "JTfGlyeTHqyy",
    "outputId": "3041cd74-1118-4957-aaf6-7c388c0fbe3a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Esophagus</th>\n",
       "      <th>Heart</th>\n",
       "      <th>Lung_L</th>\n",
       "      <th>Lung_R</th>\n",
       "      <th>SpinalCord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../processed/LCTSC-Train-S3-005/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005/structure/Esop...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005/structure/Hear...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-005/structure/Spin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../processed/LCTSC-Train-S1-004/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004/structure/Esop...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004/structure/Hear...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S1-004/structure/Spin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../processed/LCTSC-Train-S2-004/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004/structure/Esop...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004/structure/Hear...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S2-004/structure/Spin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../processed/LCTSC-Train-S3-008/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008/structure/Esop...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008/structure/Hear...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-008/structure/Spin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../processed/LCTSC-Train-S3-012/img_crp_v2.npy</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012/structure/Esop...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012/structure/Hear...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012/structure/Lung...</td>\n",
       "      <td>../processed/LCTSC-Train-S3-012/structure/Spin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Image  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/img_crp_v2.npy   \n",
       "1  ../processed/LCTSC-Train-S1-004/img_crp_v2.npy   \n",
       "2  ../processed/LCTSC-Train-S2-004/img_crp_v2.npy   \n",
       "3  ../processed/LCTSC-Train-S3-008/img_crp_v2.npy   \n",
       "4  ../processed/LCTSC-Train-S3-012/img_crp_v2.npy   \n",
       "\n",
       "                                           Esophagus  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/structure/Esop...   \n",
       "1  ../processed/LCTSC-Train-S1-004/structure/Esop...   \n",
       "2  ../processed/LCTSC-Train-S2-004/structure/Esop...   \n",
       "3  ../processed/LCTSC-Train-S3-008/structure/Esop...   \n",
       "4  ../processed/LCTSC-Train-S3-012/structure/Esop...   \n",
       "\n",
       "                                               Heart  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/structure/Hear...   \n",
       "1  ../processed/LCTSC-Train-S1-004/structure/Hear...   \n",
       "2  ../processed/LCTSC-Train-S2-004/structure/Hear...   \n",
       "3  ../processed/LCTSC-Train-S3-008/structure/Hear...   \n",
       "4  ../processed/LCTSC-Train-S3-012/structure/Hear...   \n",
       "\n",
       "                                              Lung_L  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/structure/Lung...   \n",
       "1  ../processed/LCTSC-Train-S1-004/structure/Lung...   \n",
       "2  ../processed/LCTSC-Train-S2-004/structure/Lung...   \n",
       "3  ../processed/LCTSC-Train-S3-008/structure/Lung...   \n",
       "4  ../processed/LCTSC-Train-S3-012/structure/Lung...   \n",
       "\n",
       "                                              Lung_R  \\\n",
       "0  ../processed/LCTSC-Train-S3-005/structure/Lung...   \n",
       "1  ../processed/LCTSC-Train-S1-004/structure/Lung...   \n",
       "2  ../processed/LCTSC-Train-S2-004/structure/Lung...   \n",
       "3  ../processed/LCTSC-Train-S3-008/structure/Lung...   \n",
       "4  ../processed/LCTSC-Train-S3-012/structure/Lung...   \n",
       "\n",
       "                                          SpinalCord  \n",
       "0  ../processed/LCTSC-Train-S3-005/structure/Spin...  \n",
       "1  ../processed/LCTSC-Train-S1-004/structure/Spin...  \n",
       "2  ../processed/LCTSC-Train-S2-004/structure/Spin...  \n",
       "3  ../processed/LCTSC-Train-S3-008/structure/Spin...  \n",
       "4  ../processed/LCTSC-Train-S3-012/structure/Spin...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df contains all data regarding input data\n",
    "df_train = pd.DataFrame(data_train, columns = ['Image','Esophagus','Heart','Lung_L','Lung_R','SpinalCord'])\n",
    "df_val = pd.DataFrame(data_val, columns = ['Image','Esophagus','Heart','Lung_L','Lung_R','SpinalCord'])\n",
    "df_test = pd.DataFrame(data_test, columns = ['Image','Esophagus','Heart','Lung_L','Lung_R','SpinalCord'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sUWVvb4HuXh"
   },
   "source": [
    "## Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ciTzY6P0HwSn"
   },
   "outputs": [],
   "source": [
    "def Datagen_CT(df,img_size,seg_organ,batch_size):\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        image = np.load(row[\"Image\"])\n",
    "        image = np.moveaxis(image,0,-1)\n",
    "        image = cv2.resize(image, (img_size,img_size))\n",
    "        image = np.swapaxes(image,0,-1)\n",
    "\n",
    "        mask = np.load(row[seg_organ])\n",
    "        mask = np.moveaxis(mask,0,-1)\n",
    "        mask = cv2.resize(mask , (img_size,img_size))\n",
    "        mask = np.swapaxes(mask,0,-1)\n",
    "        \n",
    "        slice_index = 0 #the index of the next slice to be examined\n",
    "\n",
    "        while slice_index < image.shape[0]:#we put mask here because image has a longer size to adjust for the last slice\n",
    "            images = image[slice_index: slice_index + batch_size,:,:]\n",
    "            masks = mask[slice_index: slice_index + batch_size,:,:]\n",
    "\n",
    "            slice_index = slice_index + batch_size\n",
    "            images = np.expand_dims(images,axis=1).astype('float32')\n",
    "            masks = np.expand_dims(masks,axis=1).astype('float32')\n",
    "\n",
    "            yield images, masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LYfkbP6IxMF"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "dE8-sry_HxwS"
   },
   "outputs": [],
   "source": [
    "class ViT_Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, init_weight_path=None, image_size=224, patch_size=16, num_channels=3, num_attention_heads = 12, num_hidden_layers=12, hidden_size=768):\n",
    "        super(ViT_Encoder,self).__init__()\n",
    "\n",
    "        \n",
    "        \n",
    "        self.config = ViTConfig(hidden_size = hidden_size, num_hidden_layers = num_hidden_layers, \n",
    "                                num_attention_heads = num_attention_heads, image_size = image_size, \n",
    "                                patch_size = patch_size, num_channels = num_channels)\n",
    "\n",
    "        self.model = ViTModel(self.config)\n",
    "        self.model.load_state_dict(torch.load(init_weight_path))\n",
    "        \n",
    "        self.linear = [nn.Linear(hidden_size,patch_size*patch_size) for _ in range(0,12)]\n",
    "        self.output_size = image_size//patch_size\n",
    "  \n",
    "    def forward(self,x):\n",
    "        x = self.model(pixel_values=x,output_hidden_states=True,output_attentions = True)\n",
    "        attn_out = [self.linear[i](x.hidden_states[i][:,1:,:]).permute(0,2,1) for i in range(0,12)]\n",
    "        attn_out = [out.reshape((out.shape[0],out.shape[1],self.output_size,self.output_size)) for out in attn_out]   \n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT_Encoder(init_weight_path='init_weight/ViT_original_pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(5,3,224,224)\n",
    "out = model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256, 14, 14])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,dim_i,dim_o,up_size):\n",
    "        \n",
    "        self.trans_conv1 = nn.ConvTranspose2d(dim_i,dim_o,kernel_size=up_size,stride=up_size)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "        self.trans_conv2 = nn.ConvTranspose2d(dim_i,dim_o,kernel_size=up_size,stride=up_size)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(dim_o)\n",
    "    \n",
    "    def forward(self,x1,x2,img):\n",
    "        \n",
    "        x1 = self.trans_conv1(x1)\n",
    "        x1 = self.batchnorm1(x1)\n",
    "        x1 = F.leaky_relu(x1)\n",
    "        \n",
    "        feat_map = img * x1\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ivInjwqcC5Pt"
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self,dim_i,dim_o,up_size):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "\n",
    "        self.trans_conv = nn.ConvTranspose2d(dim_i,dim_o,kernel_size=up_size,stride=up_size)\n",
    "        self.conv_2 = nn.Conv2d(dim_i,dim_o,kernel_size=3,padding=\"same\")\n",
    "        self.conv_3 = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "\n",
    "        self.batchnorm_2 = nn.BatchNorm2d(dim_o)\n",
    "        self.batchnorm_3 = nn.BatchNorm2d(dim_o)\n",
    "  \n",
    "    def forward(self,x,x_skip):\n",
    "        x1 = self.trans_conv(x)\n",
    "        x1 = torch.cat([x1,x_skip],dim=1)\n",
    "\n",
    "        x2 = self.conv_2(x1)\n",
    "        x2 = self.batchnorm_2(x2)\n",
    "        x2 = F.leaky_relu(x2)\n",
    "\n",
    "        x3 = self.conv_3(x2)\n",
    "        x3 = self.batchnorm_3(x3)\n",
    "        x3 = F.leaky_relu(x3)\n",
    "        return x3\n",
    "    \n",
    "class SC1(nn.Module):\n",
    "\n",
    "    def __init__(self,dim_i,dim_o):\n",
    "        super(SC1,self).__init__()\n",
    "\n",
    "        self.trans_conv1 = nn.ConvTranspose2d(dim_i,dim_i//2,kernel_size=4,stride=4)\n",
    "        self.conv_2 = nn.Conv2d(dim_i//2,dim_i//2,kernel_size=5,padding=\"same\")\n",
    "        \n",
    "        self.trans_conv2 = nn.ConvTranspose2d(dim_i//2,dim_o,kernel_size=4,stride=4)\n",
    "        self.conv_3 = nn.Conv2d(dim_o,dim_o,kernel_size=5,padding=\"same\")\n",
    "\n",
    "        self.batchnorm_2 = nn.BatchNorm2d(dim_i//2)\n",
    "        self.batchnorm_3 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "        self.trans_conv_dec = nn.ConvTranspose2d(dim_o*2,dim_o,kernel_size=2,stride=2)\n",
    "        self.batchnorm_dec = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "        self.convf = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "        self.batchnorm_f = nn.BatchNorm2d(dim_o)\n",
    "  \n",
    "    def forward(self,x,x_dec):\n",
    "        x1 = self.trans_conv1(x)\n",
    "\n",
    "        x2 = self.conv_2(x1)\n",
    "        x2 = self.batchnorm_2(x2)\n",
    "        x2 = F.leaky_relu(x2)\n",
    "        \n",
    "        x2 = self.trans_conv2(x2)\n",
    "\n",
    "        x3 = self.conv_3(x2)\n",
    "        x3 = self.batchnorm_3(x3)\n",
    "        x3 = F.leaky_relu(x3)\n",
    "        \n",
    "        x_dec = self.trans_conv_dec(x_dec)\n",
    "        x_dec = self.batchnorm_dec(x_dec)\n",
    "        x_dec = F.leaky_relu(x_dec)\n",
    "        \n",
    "        xf = x3 * x_dec\n",
    "        xf = self.convf(xf)\n",
    "        xf = self.batchnorm_f(xf)\n",
    "        xf = F.leaky_relu(xf)\n",
    "        return xf\n",
    "    \n",
    "class SC2(nn.Module):\n",
    "\n",
    "    def __init__(self,dim_i,dim_o):\n",
    "        super(SC2,self).__init__()\n",
    "\n",
    "        self.trans_conv1 = nn.ConvTranspose2d(dim_i,dim_i//2,kernel_size=4,stride=4)\n",
    "        self.conv_2 = nn.Conv2d(dim_i//2,dim_i//2,kernel_size=5,padding=\"same\")\n",
    "        \n",
    "        self.trans_conv2 = nn.ConvTranspose2d(dim_i//2,dim_o,kernel_size=2,stride=2)\n",
    "        self.conv_3 = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "\n",
    "        self.batchnorm_2 = nn.BatchNorm2d(dim_i//2)\n",
    "        self.batchnorm_3 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "        self.trans_conv_dec = nn.ConvTranspose2d(dim_o*2,dim_o,kernel_size=2,stride=2)\n",
    "        self.batchnorm_dec = nn.BatchNorm2d(dim_o)\n",
    "  \n",
    "        self.convf = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "        self.batchnorm_f = nn.BatchNorm2d(dim_o)\n",
    "  \n",
    "    def forward(self,x,x_dec):\n",
    "        x1 = self.trans_conv1(x)\n",
    "\n",
    "        x2 = self.conv_2(x1)\n",
    "        x2 = self.batchnorm_2(x2)\n",
    "        x2 = F.leaky_relu(x2)\n",
    "        \n",
    "        x2 = self.trans_conv2(x2)\n",
    "\n",
    "        x3 = self.conv_3(x2)\n",
    "        x3 = self.batchnorm_3(x3)\n",
    "        x3 = F.leaky_relu(x3)\n",
    "        \n",
    "        x_dec = self.trans_conv_dec(x_dec)\n",
    "        x_dec = self.batchnorm_dec(x_dec)\n",
    "        x_dec = F.leaky_relu(x_dec)\n",
    "        \n",
    "        xf = x3 * x_dec\n",
    "        xf = self.convf(xf)\n",
    "        xf = self.batchnorm_f(xf)\n",
    "        xf = F.leaky_relu(xf)\n",
    "        return xf\n",
    "\n",
    "class SC3(nn.Module):\n",
    "\n",
    "    def __init__(self,dim_i,dim_o):\n",
    "        super(SC3,self).__init__()\n",
    "\n",
    "        self.trans_conv1 = nn.ConvTranspose2d(dim_i,dim_i//2,kernel_size=2,stride=2)\n",
    "        self.conv_2 = nn.Conv2d(dim_i//2,dim_i//2,kernel_size=3,padding=\"same\")\n",
    "        \n",
    "        self.trans_conv2 = nn.ConvTranspose2d(dim_i//2,dim_o,kernel_size=2,stride=2)\n",
    "        self.conv_3 = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "\n",
    "        self.batchnorm_2 = nn.BatchNorm2d(dim_i//2)\n",
    "        self.batchnorm_3 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "        self.trans_conv_dec = nn.ConvTranspose2d(dim_o*2,dim_o,kernel_size=2,stride=2)\n",
    "        self.batchnorm_dec = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "        self.convf = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "        self.batchnorm_f = nn.BatchNorm2d(dim_o)\n",
    "  \n",
    "    def forward(self,x,x_dec):\n",
    "        x1 = self.trans_conv1(x)\n",
    "\n",
    "        x2 = self.conv_2(x1)\n",
    "        x2 = self.batchnorm_2(x2)\n",
    "        x2 = F.leaky_relu(x2)\n",
    "        \n",
    "        x2 = self.trans_conv2(x2)\n",
    "\n",
    "        x3 = self.conv_3(x2)\n",
    "        x3 = self.batchnorm_3(x3)\n",
    "        x3 = F.leaky_relu(x3)\n",
    "        \n",
    "        x_dec = self.trans_conv_dec(x_dec)\n",
    "        x_dec = self.batchnorm_dec(x_dec)\n",
    "        x_dec = F.leaky_relu(x_dec)\n",
    "        \n",
    "        xf = x3 * x_dec\n",
    "        xf = self.convf(xf)\n",
    "        xf = self.batchnorm_f(xf)\n",
    "        xf = F.leaky_relu(xf)\n",
    "        return xf\n",
    "    \n",
    "class SC4(nn.Module):\n",
    "\n",
    "    def __init__(self,dim_i,dim_o):\n",
    "        super(SC4,self).__init__()\n",
    "\n",
    "        self.trans_conv1 = nn.ConvTranspose2d(dim_i,dim_o,kernel_size=2,stride=2)\n",
    "        self.conv_2 = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "        self.conv_3 = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "\n",
    "        self.batchnorm_2 = nn.BatchNorm2d(dim_o)\n",
    "        self.batchnorm_3 = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "        self.trans_conv_dec = nn.ConvTranspose2d(dim_o*2,dim_o,kernel_size=2,stride=2)\n",
    "        self.batchnorm_dec = nn.BatchNorm2d(dim_o)\n",
    "        \n",
    "        self.convf = nn.Conv2d(dim_o,dim_o,kernel_size=3,padding=\"same\")\n",
    "        self.batchnorm_f = nn.BatchNorm2d(dim_o)\n",
    "  \n",
    "    def forward(self,x,x_dec):\n",
    "        x1 = self.trans_conv1(x)\n",
    "\n",
    "        x2 = self.conv_2(x1)\n",
    "        x2 = self.batchnorm_2(x2)\n",
    "        x2 = F.leaky_relu(x2)\n",
    "\n",
    "        x3 = self.conv_3(x2)\n",
    "        x3 = self.batchnorm_3(x3)\n",
    "        x3 = F.leaky_relu(x3)\n",
    "        \n",
    "        x_dec = self.trans_conv_dec(x_dec)\n",
    "        x_dec = self.batchnorm_dec(x_dec)\n",
    "        x_dec = F.leaky_relu(x_dec)\n",
    "        \n",
    "        xf = x3 * x_dec\n",
    "        xf = self.convf(xf)\n",
    "        xf = self.batchnorm_f(xf)\n",
    "        xf = F.leaky_relu(xf)\n",
    "        return xf\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "\n",
    "        #since last two maxpools are x4, the filter and strides of first two transpose convs are 4 each\n",
    "        self.dec1 = DecoderBlock(256,128,2) #14->28\n",
    "        self.dec2 = DecoderBlock(128,64,2) #28 -> 56\n",
    "        self.dec3 = DecoderBlock(64,32,2) #56 -> 112\n",
    "        self.dec4 = DecoderBlock(32,16,2) #112 -> 224\n",
    "        \n",
    "        self.sc1 = SC1(256,16)\n",
    "        self.sc2 = SC2(256,32)\n",
    "        self.sc3 = SC3(256,64)\n",
    "        self.sc4 = SC4(256,128)\n",
    "  \n",
    "    def forward(self,x,x4,x3,x2,x1): \n",
    "        x4 = self.sc4(x4,x)\n",
    "        xi = self.dec1(x,x4)\n",
    "        \n",
    "        x3 = self.sc3(x3,xi)\n",
    "        xi = self.dec2(xi,x3)\n",
    "        \n",
    "        x2 = self.sc2(x2,xi)\n",
    "        xi = self.dec3(xi,x2)\n",
    "        \n",
    "        x1 = self.sc1(x1,xi)\n",
    "        xi = self.dec4(xi,x1)\n",
    "        return xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1cSCkzDrILe7"
   },
   "outputs": [],
   "source": [
    "class SegModel(nn.Module):\n",
    "\n",
    "    def __init__(self,encoder,decoder):\n",
    "        super(SegModel,self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        self.conv1 = nn.Conv2d(256,256,kernel_size=3,stride=1,padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(256,256,kernel_size=3,stride=1,padding=\"same\")\n",
    "\n",
    "        self.batchnorm_1 = nn.BatchNorm2d(256)\n",
    "        self.batchnorm_2 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.convf = nn.Conv2d(16,1,kernel_size=1,stride=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x1,x2,x3,xf = self.encoder(x)\n",
    "\n",
    "        xm = self.conv1(xf)\n",
    "        xm = self.batchnorm_1(xm)\n",
    "        xm = F.leaky_relu(xm)\n",
    "\n",
    "        xm = self.conv2(xm)\n",
    "        xm = self.batchnorm_2(xm)\n",
    "        xm = F.leaky_relu(xm)\n",
    "\n",
    "        x_dec = self.decoder(xm,xf,x3,x2,x1)\n",
    "\n",
    "        xf = self.convf(x_dec)\n",
    "        xf = torch.sigmoid(xf)\n",
    "        return xf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mf0MTemMzpR"
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "f-RBMmAMM1oS"
   },
   "outputs": [],
   "source": [
    "def dice_loss(y_pred,y_true,smooth=1):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1)\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1)\n",
    "    \n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    result = (2. * intersection + smooth) / (torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) + smooth)\n",
    "    dice_loss = torch.sum(1-result)/y_pred.shape[0]\n",
    "    return  dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_io1jk6M5k9"
   },
   "source": [
    "## Eval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fB6x25GZM3lw"
   },
   "outputs": [],
   "source": [
    "#IOU [Between 0-1: Higher value => Better results]\n",
    "def iou_metric(y_pred,y_true):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "    \n",
    "    y_pred_f[y_pred_f >= 0.5] = 1\n",
    "    y_pred_f[y_pred_f < 0.5] = 0\n",
    "\n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    union = torch.sum(y_true_f,1) + torch.sum(y_pred_f,1) - torch.sum(y_true_f * y_pred_f,1)\n",
    "    \n",
    "    iou_score = 0\n",
    "    for i in range(union.shape[0]):\n",
    "        if union[i] == 0:\n",
    "            iou_score += 1\n",
    "        else:\n",
    "            iou_score += intersection[i].item()/union[i].item()\n",
    "    iou_score = iou_score/y_pred.shape[0]\n",
    "    return iou_score\n",
    "\n",
    "#Dice [Between 0-1: Higher value => Better results]\n",
    "def dice_metric(y_pred,y_true):\n",
    "    y_true_f = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred_f = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "    \n",
    "    y_pred_f[y_pred_f >= 0.5] = 1\n",
    "    y_pred_f[y_pred_f < 0.5] = 0\n",
    "\n",
    "    intersection = torch.sum(y_true_f * y_pred_f,1)\n",
    "    area_sum = torch.sum(y_true_f,1) + torch.sum(y_pred_f,1)\n",
    "    \n",
    "    dice_score = 0\n",
    "    for i in range(area_sum.shape[0]):\n",
    "        if area_sum[i] == 0:\n",
    "            dice_score += 1\n",
    "        else:\n",
    "            dice_score += 2. * intersection[i].item() / area_sum[i].item()\n",
    "    dice_score = dice_score/y_pred.shape[0]\n",
    "    return  dice_score\n",
    "\n",
    "#Precision [Between 0-1: Larger value => Better results]\n",
    "def precision_metric(y_pred,y_true):\n",
    "    y_true = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    tp = torch.sum(y_pred * y_true,1)\n",
    "    denom = torch.sum(y_pred,1)\n",
    "    true_sum = torch.sum(y_true,1)\n",
    "    \n",
    "    pre = 0\n",
    "    for i in range(denom.shape[0]):\n",
    "        if denom[i] == 0 and true_sum[i] == 0:\n",
    "            pre += 1\n",
    "        elif denom[i] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            pre += tp[i].item()/denom[i].item()\n",
    "    pre_score = pre/y_pred.shape[0]\n",
    "    return pre_score\n",
    "\n",
    "#Recall [Between 0-1: Larger value => Better results]\n",
    "def recall_metric(y_pred,y_true):\n",
    "    y_true = torch.flatten(y_true,start_dim=1).detach().cpu()\n",
    "    y_pred = torch.flatten(y_pred,start_dim=1).detach().cpu()\n",
    "\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "    tp = torch.sum(y_pred * y_true,1)\n",
    "    denom = torch.sum(y_true,1)\n",
    "    \n",
    "    re = 0\n",
    "    for i in range(denom.shape[0]):\n",
    "        if denom[i] == 0:\n",
    "            re += 1\n",
    "        else:\n",
    "            re += tp[i].item()/denom[i].item()\n",
    "    re_score = re/y_pred.shape[0]\n",
    "    return re_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCUXgI3GM-5I"
   },
   "source": [
    "## Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "M5K9qZ9YNCN2"
   },
   "outputs": [],
   "source": [
    "def eval(model,val_df,img_size,seg_organ,batch_size,epoch=0,epochs=0):\n",
    "    #epoch and epoch size is passed if this function is called during training in between epochs\n",
    "    model.eval()\n",
    "    test_dataloader = Datagen_CT(df=val_df,img_size=img_size,seg_organ=seg_organ,batch_size=batch_size)\n",
    "\n",
    "    iou_val = 0\n",
    "    dice_val = 0\n",
    "    pre_val = 0\n",
    "    re_val = 0\n",
    "\n",
    "    count = 0\n",
    "    for batch_idx, (X,y) in enumerate(test_dataloader):\n",
    "        X = to_device(torch.tensor(np.repeat(X,repeats=3,axis=1), requires_grad=True),get_default_device())\n",
    "        y = to_device(torch.tensor(y, requires_grad=True),get_default_device())\n",
    "\n",
    "        output = model(X)\n",
    "        iou_val += iou_metric(output,y)\n",
    "        dice_val += dice_metric(output,y)\n",
    "        pre_val += precision_metric(output,y)\n",
    "        re_val += recall_metric(output,y)\n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    dice_score = dice_val/count\n",
    "    iou_score = iou_val/count\n",
    "    pre_score = pre_val/count\n",
    "    re_score = re_val/count\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('End of Epoch [{}/{}]   Dice Metric: {:.4f}  IoU Metric: {:.4f}  Precision Metric: {:.4f}  Recall Metric: {:.4f}'.format(epoch+1,epochs,dice_score,iou_score,pre_score,re_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwcQIeR7NGAV"
   },
   "source": [
    "## Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ExHWQu2rNIDU"
   },
   "outputs": [],
   "source": [
    "def fit(model,img_size,seg_organ,batch_size,loss_fn,optimizer,scheduler,epochs,train_df,val_df,validate=False,print_every=1,print_epoch=1):\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        train_dataloader = Datagen_CT(df=train_df,img_size=img_size,seg_organ=seg_organ,batch_size=batch_size)\n",
    "        \n",
    "        total_loss = 0\n",
    "        max_out = 0\n",
    "        for batch_idx, (X,y) in enumerate(train_dataloader):\n",
    "            X = to_device(torch.tensor(np.repeat(X,repeats=3,axis=1), requires_grad=True),get_default_device())\n",
    "            y = to_device(torch.tensor(y, requires_grad=True),get_default_device())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            loss = loss_fn(output,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            max_out = max(max_out,torch.max(output))\n",
    "\n",
    "            if batch_idx != 0 and batch_idx % print_every == 0:\n",
    "                print('Epoch [{}/{}]   Batch {}   Loss: {:.4f}    Max: {:.4f}'.format(epoch+1,epochs,batch_idx,total_loss/print_every,max_out))\n",
    "                total_loss = 0\n",
    "                max_out = 0\n",
    "\n",
    "                if epoch % print_epoch == 0 :\n",
    "                    plt.subplot(1,3,1)\n",
    "                    plt.imshow(X.cpu().detach().numpy()[0][0])\n",
    "\n",
    "                    plt.subplot(1,3,2)\n",
    "                    plt.imshow(y.cpu().detach().numpy()[0][0])\n",
    "\n",
    "                    plt.subplot(1,3,3)\n",
    "                    plt.imshow(output.cpu().detach().numpy()[0][0])\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if validate:\n",
    "            eval(model=model,val_df=val_df,img_size=img_size,seg_organ=seg_organ,batch_size=batch_size,epoch=epoch,epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1g6AOgx3Oxr7"
   },
   "source": [
    "## SingleFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Z6wm8xrBOz0W"
   },
   "outputs": [],
   "source": [
    "def single_fit(model,img_size,seg_organ,batch_size,loss_fn,optimizer,scheduler,epochs,img,mask):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "\n",
    "        total_loss = 0\n",
    "        max_out = 0\n",
    "\n",
    "        X = to_device(torch.tensor(np.repeat(img,repeats=3,axis=1), requires_grad=True),get_default_device())\n",
    "        y = to_device(torch.tensor(mask, requires_grad=True),get_default_device())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = loss_fn(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        max_out = max(max_out,torch.max(output))\n",
    "\n",
    "    \n",
    "        print('Epoch [{}/{}]   Loss: {:.4f}    Max: {:.4f}'.format(epoch+1,epochs,total_loss,max_out))\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(X.cpu().detach().numpy()[0][0])\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(y.cpu().detach().numpy()[0][0])\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(output.cpu().detach().numpy()[0][0])\n",
    "\n",
    "        plt.show()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3z7K91mUNK-z"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TkOdbUUKNKb7"
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "img_size = 224\n",
    "epochs = 100\n",
    "seg_organ = 'Esophagus'\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rirudFxbNOZ4"
   },
   "outputs": [],
   "source": [
    "#Model Specific\n",
    "enc = ViT_Encoder(init_weight_path='init_weight/ViT_original_pretrained')\n",
    "dec = Decoder()\n",
    "model = SegModel(enc,dec)\n",
    "model = to_device(model,get_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WCa3OysENSvb"
   },
   "outputs": [],
   "source": [
    "#Training Specific\n",
    "loss_fn = dice_loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8R_4N-clNUuT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch [1/100]   Dice Metric: 0.0588  IoU Metric: 0.0311  Precision Metric: 0.0311  Recall Metric: 0.9973\n",
      "End of Epoch [2/100]   Dice Metric: 0.3330  IoU Metric: 0.2901  Precision Metric: 0.3133  Recall Metric: 0.4707\n",
      "End of Epoch [3/100]   Dice Metric: 0.3332  IoU Metric: 0.2992  Precision Metric: 0.3099  Recall Metric: 0.4963\n",
      "End of Epoch [4/100]   Dice Metric: 0.3109  IoU Metric: 0.2927  Precision Metric: 0.3089  Recall Metric: 0.3411\n",
      "End of Epoch [5/100]   Dice Metric: 0.4817  IoU Metric: 0.4088  Precision Metric: 0.4950  Recall Metric: 0.5675\n",
      "End of Epoch [6/100]   Dice Metric: 0.4386  IoU Metric: 0.3714  Precision Metric: 0.4430  Recall Metric: 0.5576\n",
      "End of Epoch [7/100]   Dice Metric: 0.4769  IoU Metric: 0.3951  Precision Metric: 0.4746  Recall Metric: 0.6285\n",
      "End of Epoch [8/100]   Dice Metric: 0.4798  IoU Metric: 0.4058  Precision Metric: 0.4849  Recall Metric: 0.5840\n",
      "End of Epoch [9/100]   Dice Metric: 0.4321  IoU Metric: 0.3728  Precision Metric: 0.4590  Recall Metric: 0.5053\n",
      "End of Epoch [10/100]   Dice Metric: 0.4151  IoU Metric: 0.3604  Precision Metric: 0.4603  Recall Metric: 0.4774\n",
      "End of Epoch [11/100]   Dice Metric: 0.5364  IoU Metric: 0.4416  Precision Metric: 0.5163  Recall Metric: 0.7053\n",
      "End of Epoch [12/100]   Dice Metric: 0.5453  IoU Metric: 0.4524  Precision Metric: 0.5427  Recall Metric: 0.6695\n",
      "End of Epoch [13/100]   Dice Metric: 0.4359  IoU Metric: 0.3859  Precision Metric: 0.5174  Recall Metric: 0.4311\n",
      "End of Epoch [14/100]   Dice Metric: 0.5295  IoU Metric: 0.4519  Precision Metric: 0.5713  Recall Metric: 0.5855\n",
      "End of Epoch [15/100]   Dice Metric: 0.4185  IoU Metric: 0.3726  Precision Metric: 0.4912  Recall Metric: 0.4203\n",
      "End of Epoch [16/100]   Dice Metric: 0.4003  IoU Metric: 0.3591  Precision Metric: 0.4703  Recall Metric: 0.4059\n",
      "End of Epoch [17/100]   Dice Metric: 0.4142  IoU Metric: 0.3709  Precision Metric: 0.4928  Recall Metric: 0.4067\n"
     ]
    }
   ],
   "source": [
    "fit(model=model, img_size=img_size, seg_organ=seg_organ, batch_size=batch_size,\n",
    "    loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler,\n",
    "    epochs=epochs, train_df=df_train, val_df=df_val, \n",
    "    validate=True, print_every=2000, print_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(),lr=1e-5 * 5)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[], gamma=0.1)\n",
    "\n",
    "# fit(model=model, img_size=img_size, seg_organ=seg_organ, batch_size=batch_size,\n",
    "#     loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler,\n",
    "#     epochs=epochs, train_df=df_train, val_df=df_val, \n",
    "#     validate=True, print_every=2000, print_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bP24XTuLPfIK"
   },
   "outputs": [],
   "source": [
    "# d = Datagen_CT(df=df_train,img_size=img_size,seg_organ=seg_organ,batch_size=1)\n",
    "# for i in range(0,100):\n",
    "#     img, mask = next(d)\n",
    "\n",
    "# single_fit(model=model, img_size=img_size, seg_organ=seg_organ, batch_size=batch_size,\n",
    "#           loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler,\n",
    "#           epochs=500, img=img, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ViT Segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
